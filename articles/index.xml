<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>文章 on ATTS</title>
    <link>https://codenow.me/articles/</link>
    <description>Recent content in 文章 on ATTS</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 15 Mar 2019 07:28:29 +0000</lastBuildDate>
    
	<atom:link href="https://codenow.me/articles/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Windows安装spark</title>
      <link>https://codenow.me/articles/spark_installation_onwindows/</link>
      <pubDate>Sun, 07 Apr 2019 20:48:40 +0800</pubDate>
      
      <guid>https://codenow.me/articles/spark_installation_onwindows/</guid>
      <description> 下载安装Java，安装版本为8 Java8下载地址 安装教程详见：菜鸟教程—Java安装
下载spark安装包 spark2.3.3下载地址
建议安装2.3.3版本，高版本的2.4.0在运行时会报错Py4j error。 下载后解压文件夹，并将路径配置到系统变量中。
系统环境变量中配置路径如下：
下载Hadoop支持包 百度网盘下载地址 提取码：ezs5
下载后解压，并添加系统变量：
下载并安装pycharm和anaconda 具体安装教程可自行百度。
安装后，将spark下的python中的pyspark拷贝到安装的python路径下的：Lib\site-packages 然后运行pip install py4j
配置pycharm运行spark环境 根据上图进行配置后即可运行spark程序。
配置日志显示级别 在spark\conf目录下创建log4j.properties配置文件，该目录下有template模板，可以直接复制。
然后将其中的：log4j.rootCategory=INFO, console 修改为 log4j.rootCategory=WARN, console
配置cmd下pyspark在jupyter下运行 编辑spark目录下：bin\pyspark2.cmd 修改其中对应部分为以下格式：
rem Figure out which Python to use. if &amp;quot;x%PYSPARK_DRIVER_PYTHON%&amp;quot;==&amp;quot;x&amp;quot; ( set PYSPARK_DRIVER_PYTHON=jupyter set PYSPARK_DRIVER_PYTHON_OPTS=notebook if not [%PYSPARK_PYTHON%] == [] set PYSPARK_DRIVER_PYTHON=%PYSPARK_PYTHON% )  </description>
    </item>
    
    <item>
      <title>Golang Linux Namespace Usage</title>
      <link>https://codenow.me/articles/golang-namespace/</link>
      <pubDate>Sun, 07 Apr 2019 20:22:21 +0800</pubDate>
      
      <guid>https://codenow.me/articles/golang-namespace/</guid>
      <description>总所周知 Docker 最早诞生于 Linux 平台，利用的是 Linux LXC 技术作为基础。Docker 作为一种 “轻量级虚拟机” 跑在通用操作系统中，那么势必就要对容器进行隔离，保证在宿主机内的独立性。
Namespace Overview 在 Linux Kernel 中有一组名为 Namespace 的系统调用 API。主要作用是封装了全局的系统资源的调用分配，在一个进程中隔离了其他进程的可见性，让自己 “拥有” 整个计算机的资源的能力。一个典型的用途就是容器的实现。
namespace 一种只有 4 个 API：
 clone：创建一个隔离的进程，可以通过参数控制所拥有的资源 setns：允许一个进程到现有的 namespace unshare：从现有 namespace 中移除一个进程 ioctl：用法发现 namespace 信息  接下来主要讨论如何创建一个具有隔离性的进程，也就是 clone 这个系统调用的用法。
clone 创建一个新的 namespace（进程），可以对其控制几个方面的资源（通过 CLONE_NEW* 这系列参数）。
 IPC：CLONE_NEWIPC，System V IPC 和 POSIX message queue Network：CLONE_NEWNET，网络设备等 Mount：CLONE_NEWNS，挂载点 PID：CLONE_NEWPID，进程的 ID User：CLONE_NEWUSER：用户或组的 ID UTS：CLONE_NEWUTS：Hostname 和 NIS domain  这里 CLONE_NEWNS 比较奇特，这是最早的一个参数，后面也想不到还有更多粒度的资源控制，所以这是一个历史遗留问题。
Namespace Usage 由于 Namespace 是 Linux 的系统调用，所以在其他操作系统是无法编译通过的。可以在 build 时候通过设置 GOOS = linux 解决，但是运行还是要放在 Linux 上运行。</description>
    </item>
    
    <item>
      <title>TiDB 源码学习：聚合查询</title>
      <link>https://codenow.me/articles/tidb-aggregation/</link>
      <pubDate>Sun, 07 Apr 2019 15:53:09 +0800</pubDate>
      
      <guid>https://codenow.me/articles/tidb-aggregation/</guid>
      <description>没了解过 Aggregation 的执行细节之前，感觉 Aggregation 比较神奇，它和普通的 SPJ 查询不太一样，Aggregation 会对数据分组并聚合计算，经过 Aggregation，整个数据的 schema 都会发生改变。
但其实，常见的 Aggregation 也并不复杂，从代码里看，和 Aggregation 相关的数据结构是这样的：
// LogicalAggregation represents an aggregate plan. type LogicalAggregation struct { logicalSchemaProducer AggFuncs []*aggregation.AggFuncDesc GroupByItems []expression.Expression // groupByCols stores the columns that are group-by items.  groupByCols []*expression.Column possibleProperties [][]*expression.Column inputCount float64 // inputCount is the input count of this plan. } type basePhysicalAgg struct { physicalSchemaProducer AggFuncs []*aggregation.AggFuncDesc GroupByItems []expression.Expression } // PhysicalHashAgg is hash operator of aggregate.</description>
    </item>
    
    <item>
      <title>互联网之子 Aaron Swarts 想要看到的世界</title>
      <link>https://codenow.me/articles/aaron_huoju/</link>
      <pubDate>Sun, 07 Apr 2019 14:19:45 +0900</pubDate>
      
      <guid>https://codenow.me/articles/aaron_huoju/</guid>
      <description>互联网之子 Aaron Swarts 想要看到的世界 作者: Jade &amp;amp; 霍炬 链接：互联网之子 Aaron Swarts 想要看到的世界 
Jade 和我偶尔会聊起一些宏大的话题，最近聊到了 Aaron 和互联网创建者们的一些历史。她觉得应该正经的来一次对话，记录下来分享给其他人。我们约了个时间，原计划聊 2 个小时，实际上聊了 5 个小时。最后形成了一篇交谈形式的文字，她称之为文字版的 Podcast。我很喜欢这种形式，我也更认同文字的价值，更好分享，更好检索，也更好修改或者摘录使用。以后我们应该还会继续这样的对话，这次聊天里面很多东西都可以继续讲下去。希望你也喜欢这个形式。
网络和 BBS 在我们现在知道的互联网诞生之前就存在了，普通人有机会接触网络的历史，至今也有 30 多年了。虚拟世界的时间进度远远比现实世界快，在中国，也有“互联网是属狗的，一年当作七年用这个说法”。按照这个比例推测，换算到现实世界，互联网实际上走过了相当于 200 年左右的历史了。对它的研究已经可以产生一个“互联网考古学”之类的新学科了，然而没有多少人意识到这件事，也没多少人对这些历史和人物有兴趣。尽管我认为这些非常重要，其中有太多的教训和经验今天仍然可以学习。而且，这些历史也不应该被忘掉。
Usenet 今天已经变成了下载者的乐园，但是它的废墟里埋葬了太多的历史和欢笑血泪。一些人已经消失，一些人还在积极工作，一些人已经走上了另外一条道路，还有一些人已经离开了我们。如果你从 80 年代就对整个网络世界有所了解，你会发现到今天一切都是相连的，从拨号 BBS 到区块链，有一条暗线始终存在。差不多也到了挖掘这些故事的时候了。
01 自由的代价 Jade：首先问个题外话，你为什么会选择在寒冷的加拿大生活和开发产品？
霍炬：几年前我觉得世界似乎变得越来越混乱，我和太太就想找一个“安全的地方”躲起来。于是我去读了所有可能去的国家的历史和政治制度，最后认为最安全的两个地方是新西兰和加拿大。但新西兰太偏远，科技和互联网不够发达，加拿大科技水平很高，创新能力也好，于是，就加拿大了。
Jade：没想到一个八卦问题引发了如此深刻的答案，吓了我一跳。之所以咱们决定有这次对谈，我记得是有一次我们聊起了 Aaron Swarts，你给我推荐了关于他的纪录片（互联网之子 The Internet&amp;rsquo;s Own Boy: The Story of Aaron Swartz (2014)），然后就一发不可收拾地聊起了一大堆宏大的主题。能不能从你的角度再介绍一下 Aaron 这个人，我们都知道他是一个互联网天才，14 岁参与制订 RSS 标准，26 岁在 MIT 事件的压力下自杀。为什么你觉得这个人很重要？他带来了什么？
霍炬：Aaron 最常见的介绍是“reddit 联合创始人，RSS 参与者，Markdown 标准参与者”。但是这些不是我想说的重点，重点是他是一个承接上一代和下一代的人物。应该是承接互联网创建者们的理念，并且用来改造世界的人。
Aaron 深受 John Perry Barlow（电子前线基金会 EFF 的创始人）的影响。在 Aaron 中学时代，John 到他们学校演讲，Aaron 听了这个演讲之后，深受影响。后来 Aaron 的爸爸说那天他回家就像变了一个人一样。以及后来 Aaron 和 Tim Berners-Lee 在一起工作，等等。按照他的年龄，很难想象和这些互联网的创建者们一起工作和活动。但是他和他们相处很好，这些人也都喜欢他。</description>
    </item>
    
    <item>
      <title>两阶段提交协议</title>
      <link>https://codenow.me/articles/2pc/</link>
      <pubDate>Sun, 31 Mar 2019 22:12:05 +0800</pubDate>
      
      <guid>https://codenow.me/articles/2pc/</guid>
      <description>两阶段提交协议
在分布式系统中每个节点都可以知道自己的操作是成功还是失败，但是无法知道其他节点的状态。为了保证一个事务的 ACID 特性，一个节点发生失败就要在所有节点上执行 rollback 操作。需要引入一个 协调者 来维护各个 参与者 的状态，以保证最终一致。
2pc 并不是万能的，需要满足一定的条件才可以使用：
 一个节点是协调者，其他节点作为参与者，相互之前可以通信 每个节点要有 redo log 机制，而且存在持久化存储中 节点不会永久损坏，一定时间会重启恢复  Tow-phase Commit Protocol 首先引入几个概念：
 协调者：维护所有节点 参与者：执行具体操作的节点 prepare phase：准备阶段，写入日志，资源加锁 commit phase：执行阶段，根据协调者指令执行，资源解锁  上图中 ① 和 ② 表示 prepare phase，③ 和 ④ 表示 commit phase。
在 prepare phase 阶段，协调者发出信息让参与者准备。参与者接受到信息以后一般会做两件事情：
 根据需要执行的操作生成 redo 日志，用于后续 commit 或者 rollback 给所需的资源上锁，防止其他程序获取  参与者完成这两个操作会把结果通知协调者。
当协调者接受到参与者在 prepare phase 阶段的响应（无论 Yes 还是 No），就会进入 commit phase 阶段。在该阶段，如果接受到 prepare phase 的响应所有都是 Yes 时候，会发出 Commit 指令；只要收到一个 No，发出的就是 Rollback 指令。</description>
    </item>
    
    <item>
      <title>Python3 Crontab</title>
      <link>https://codenow.me/articles/python3-crontab/</link>
      <pubDate>Sun, 31 Mar 2019 21:43:04 +0800</pubDate>
      
      <guid>https://codenow.me/articles/python3-crontab/</guid>
      <description>这周需要在容器中跑一个定时脚本
现成的方式有很多： 1. 直接使用 ubuntu:14.04 的镜像，内置 crontab 和 python3.4 2. 想用 python3.6 的话，可以用 python:3.6 的镜像装一个 crontab 也成 3. dockerhub 上别人应该也有这种需求，捞一个就成
不过我还是想自己拼一个，要求： 1. 需要包含 crontab 和 python3.6 2. 需要能支持使用 pip 安装其他扩展包 3. 镜像要尽量小
思路以及需要注意的地方大概是： 1. 装上各种必要的东西 2. 设置时区 3. 配置好 crontabfile 4. 运行时启动 crond，并用 tail -f 来保证容器不退出
目前只是做了个能用的，用 python3.6-alpine 做源，往上怼了点够自己使用的东西，先实现了需求
下一步是直接用 alpine 或者 buildpack-deps 来构建镜像，以此精简，留着 TODO 吧
我写了个 demo 放到了 github 上: https://github.com/WokoLiu/python3-cron ，也同步到了 dockerhub 上 docker pull woko/python3-cron
文件结构是这样的：
. ├── Dockerfile ├── crontabfile ├── scripts.</description>
    </item>
    
    <item>
      <title>TiDB 源码学习：常见子查询优化</title>
      <link>https://codenow.me/articles/tidb-subquery-optimization/</link>
      <pubDate>Sun, 31 Mar 2019 13:19:47 +0800</pubDate>
      
      <guid>https://codenow.me/articles/tidb-subquery-optimization/</guid>
      <description>根据 TiDB 中的子查询优化技术 这篇文章的介绍，TiDB 在处理关联子查询时引入了 Apply 算子。然后使用关系代数将 Apply 算子等价转换成其他算子，从而达到去关联化的目的。理论上，所有的关联子查询都可以去关联化，具体的理论知识可以看这篇博客：SQL 子查询的优化。
本文从代码角度，梳理一下常见关联子查询的优化。处理过程主要有两个阶段：
 重写阶段：在将语法树转换成逻辑查询计划时，将子查询重写成带有 Apply 算子的查询计划，这部分主要是由 expressionRewriter 负责 去关联化：在优化逻辑查询计划时，尝试将 Apply 算子替换成其他算子，从而去关联化，这部分主要有 decorrelateSolver 负责  expressionRewriter 简介 expressionRewriter 负责将子查询重语法树写成带有 Apply 算子的查询计划。为了实现这一功能，需要能够遍历语法树，expressionRewriter 实现了 Visitor 接口，能够遍历语法树中的各个节点，在遍历过程当中完成重写工作，它的核心的方法主要是 Enter 和 Leave。
Visitor 接口一般会被这样使用：
func (n *CompareSubqueryExpr) Accept(v Visitor) (Node, bool) { newNode, skipChildren := v.Enter(n) if skipChildren { return v.Leave(newNode) } n = newNode.(*CompareSubqueryExpr) node, ok := n.L.Accept(v) //...  n.L = node.(ExprNode) node, ok = n.</description>
    </item>
    
    <item>
      <title>Spark累加器和广播变量</title>
      <link>https://codenow.me/articles/spark-broadcast_accumulator/</link>
      <pubDate>Sat, 30 Mar 2019 11:21:36 +0800</pubDate>
      
      <guid>https://codenow.me/articles/spark-broadcast_accumulator/</guid>
      <description>累加器 累加器提供将工作节点的值聚合到驱动器程序中的功能，且实现语法简单。
示例图：
#python中累加空行 file = sc.textFile(inputfile) blankLines = sc.accumulator(0) # 创建Accumulator(Int) def extractCallSigns(line): global blankLines if line == &amp;#34;&amp;#34;: blankLines += 1 return line.split(&amp;#39; &amp;#39;) callSigns = file.flatMap(extractCallSigns) callSigns.saveAsTextFile(outputPath) print(&amp;#39;blank Lines : %d&amp;#39; %blankLines.value) 实际使用中可以创建多个累加器进行计数
validSignCount = sc.Accumulator(0) invalidSignCount = sc.Accumulator(0) 广播变量 简介 正常情况中，spark的task会在执行任务时，将变量进行拷贝。当每个task都从主节点拷贝时，程序的通信和内存负担很重。 使用广播变量后，主节点会将变量拷贝至工作节点，任务从工作节点获得变量，而不用再次拷贝，此时变量被拷贝的次数取决于工作节点的个数。
#在Python中使用广播变量 signPrefixes = sc.broadcast(loadCallSignTable()) def processSignCount(sign_count, signPrefixes): country = lookupCountry(sign_count[0], signPrefixes.value) count = sign_count[1] return (country, count) countryContactCounts = (contactCounts.map(processSignCount).reduceByKey((lambda x, y:x+y))) countryContactCounts.saveAsTextFile(ooutputPath) 基于分区进行操作 基于分区对数据进行操作可以让我们避免为每个数据元素进行重复的配置工作。 Spark提供基于分区的map和foreach。</description>
    </item>
    
    <item>
      <title>How to Use Hugo</title>
      <link>https://codenow.me/articles/how-to-use-hugo/</link>
      <pubDate>Thu, 28 Mar 2019 23:51:40 +0800</pubDate>
      
      <guid>https://codenow.me/articles/how-to-use-hugo/</guid>
      <description>一、介绍 1. 优点   Hugo是一个用Go语言编写的静态网站生成器，它使用起来非常简单，相对于Jekyll复杂的安装设置来说，Hugo仅需要一个二进制文件hugo(hugo.exe)即可轻松用于本地调试和生成静态页面。 Hugo生成静态页面的效率很高，几乎是瞬间完成的，而之前用Jekyll需要等待。 Hugo自带watch的调试模式，可以在我修改MarkDown文章之后切换到浏览器，页面会检测到更新并且自动刷新，呈现出最终效果，能极大的提高博客书写效率。 再加上Hugo是使用Go语言编写，已经没有任何理由不使用Hugo来代替Jekyll作为我的个人博客站点生成器了。   2. 静态网站文件的两种方式：   放到自己的服务器上提供服务：需要自己购买服务器 把网站托管到 GitHub Pages：需要将静态页面文件 push 到 GitHub 的博客项目的 gh-pages 分支并确保根目录下有 index.html 文件。   3. 官网   Hugo语言官方中文文档地址：http://www.gohugo.org/ Hugo官方主页：https://gohugo.io/   二、安装Hugo 1. 二进制安装（推荐：简单、快速） 到 Hugo Releases (https://github.com/gohugoio/hugo/releases)下载对应的操作系统版本的Hugo二进制文件（hugo或者hugo.exe）
 下载解压后添加到 Windows 的系统环境变量的 PATH 中即可，不需安装。 可以直接放在C:\Users\chunt\go\bin下，这样就不需要添加系统环境变量  Mac下直接使用 Homebrew 安装：
 brew install hugo 二进制在 $GOPATH/bin/, 即C:\Users\chunt\go\bin  2. 源码安装(不好用，go get有些下载不下来) 源码编译安装，首先安装好依赖的工具：
 Git Go 1.</description>
    </item>
    
    <item>
      <title>使用 RMDBS 存在树结构数据</title>
      <link>https://codenow.me/articles/rmdbs-tree-datastruct/</link>
      <pubDate>Sun, 24 Mar 2019 23:41:36 +0800</pubDate>
      
      <guid>https://codenow.me/articles/rmdbs-tree-datastruct/</guid>
      <description>在关系型数据库中存储树形结构是比较麻烦的事情，因为数据库都是基于行存储的结构，要满足树形数据结构的添加、删除、查询、修改是一件比较棘手的事情。
已经有一些解决方案可以解决：
这篇文章介绍一下，使用「闭包表」来处理树形结构存储。
选择「闭包表」主要是基于查询、插入、删除、移动都比较简单，更要的是都可以使用一条 SQL 就能处理完成。
CREATE TABLE Comments ( comment_id SERIAL PRIMARY KEY, comment TEXT NOT NULL ); 树形结构典型就是评论和部门成员关系，以评论为例，我们同时又要支持完整增删改查的功能，大致结构如下： 为了满足这种复杂的关系，需要有另外一个表来存储这种结构。
CREATE TABLE TreePaths ( ancestor BIGINT NOT NULL, descendant BIGINT NOT NULL, PRIMARY KEY(ancestor, descendant), FOREIGN KEY (ancestor) REFERENCES Comments(comment_id), FOREIGN KEY (descendant) REFERENCES Comments(comment_id) ); ancestor 作为每个评论节点的祖先，descendant 作为每个评论节点的后代。
 这里的祖先和后代都是泛指所有祖先和后代，而不是特指直接的祖先和后代
 接着构造一批数据插入 Comments 和 Tree Paths 中
insert into comments(comment_id, comment) values (1, &amp;#39;这个 Bug 的成因 是什么&amp;#39;); insert into comments(comment_id, comment) values (2, &amp;#39;我觉得是一个空指针&amp;#39;); insert into comments(comment_id, comment) values (3, &amp;#39;不，我查过了&amp;#39;); insert into comments(comment_id, comment) values (4, &amp;#39;我们需要查无效输入&amp;#39;); insert into comments(comment_id, comment) values (5, &amp;#39;是的，那是个问题&amp;#39;); insert into comments(comment_id, comment) values (6, &amp;#39;好，查一下吧&amp;#39;); insert into comments(comment_id, comment) values (7, &amp;#39;解决了&amp;#39;); insert into treepaths(ancestor, descendant) values (1, 1); insert into treepaths(ancestor, descendant) values (1, 2); insert into treepaths(ancestor, descendant) values (1, 3); insert into treepaths(ancestor, descendant) values (1, 4); insert into treepaths(ancestor, descendant) values (1, 5); insert into treepaths(ancestor, descendant) values (1, 6); insert into treepaths(ancestor, descendant) values (1, 7); insert into treepaths(ancestor, descendant) values (2, 2); insert into treepaths(ancestor, descendant) values (2, 3); insert into treepaths(ancestor, descendant) values (3, 3); insert into treepaths(ancestor, descendant) values (4, 4); insert into treepaths(ancestor, descendant) values (4, 5); insert into treepaths(ancestor, descendant) values (4, 6); insert into treepaths(ancestor, descendant) values (4, 7); insert into treepaths(ancestor, descendant) values (5, 5); insert into treepaths(ancestor, descendant) values (6, 6); insert into treepaths(ancestor, descendant) values (6, 7); insert into treepaths(ancestor, descendant) values (7, 7); 这里需要解释一下 treepaths 存储关系的逻辑：</description>
    </item>
    
    <item>
      <title>[Go]Exercise of a Tour of Go</title>
      <link>https://codenow.me/articles/exercise_of_a_tour_of_go/</link>
      <pubDate>Sun, 24 Mar 2019 22:58:30 +0800</pubDate>
      
      <guid>https://codenow.me/articles/exercise_of_a_tour_of_go/</guid>
      <description>这周学了学 golang，做个记录
学习网站：https://tour.golang.org
对应的中文版：https://tour.go-zh.org
这周主要学习内容是刷了一遍上面这个教程，虽然够官方，但讲解并不细致，很多需要自行 google
顺便，第一次打开教程和在线运行代码都需要科学上网，但打开一次后所有内容就都被缓存下来了，火车上都可以翻页学习。也不方便的话可以用中文版，或者本地安装，教程上也都有说。
知识点记录 go 项目结构  必须要有 package import 用的是字符串 首字母大写的是导出名(exported name)，可以被别的包使用，有点类似于 python 的 all 只有 package main 可以被直接运行 运行入口 func main() {}  基础部件  函数以 func 定义，每个参数后必须带类型，必须规定返回值类型，可返回多个值，返回值可预先命名，函数是第一类对象(first class object) 变量以 var 定义，定义时必须规定类型，可在定义时赋值，函数内的变量可以不用 var 而用 := 来定义+赋值 常量以 const 定义，不能使用 := 语法，仅支持基础类型 基础类型是 bool, string 和各种数字，byte = uint8, tune = int32 类似于 null, None 的，是 nil  语法  if 不需要小括号，但必须有大括号；if 中可以有一条定义变量的语句，此变量仅在 if 和 else 中可用 for 是唯一的循环结构，用法基本等同于 Java 里的 for + while，同样没有小括号，但有大括号，for {} 是无限循环 switch 的每个 case 后等同于自带 break，但可以用 fallthrough 直接跳过判断而执行下一条 case 内的语句；没有匹配到任何一个 case 时会运行 default 里的内容；没有条件的 switch 可以便于改写 if-elseif-else defer 可将其后的函数推迟到外层函数返回之后再执行，多个 defer 会被压入栈中，后进先出执行 select-case 语句可同时等待多个 chan，并在所有准备好的 case 中随机选一个执行 for-range 可以对 array, map, slice, string, chan 进行遍历 make 可用来为 slice, map, chan 类型分配内存及初始化对象，返回一个引用，对这三种类型使用make时，后续参数含义均不同  其他数据类型  pointer 类似 C，没有指针运算 struct 内的字段使用 .</description>
    </item>
    
    <item>
      <title>代码「阅读」覆盖率</title>
      <link>https://codenow.me/articles/code-reading-coverage/</link>
      <pubDate>Fri, 22 Mar 2019 10:42:05 +0800</pubDate>
      
      <guid>https://codenow.me/articles/code-reading-coverage/</guid>
      <description>最近本人在阅读一些开源项目的代码，说到如何阅读开源代码，特别是超出自己能力范围的开源项目，可以说的内容还是挺多的。今天分享一个比较「偏」的：代码「阅读」覆盖率。
看一个代码库，刚开始可能是一头雾水，再咬咬牙坚持一下，一般能梳理出大致的脉络，比如服务的启动流程是怎样的，服务主要由那几个组件构成，它们之间是如何通信协作的。再往后则是一点一点了解代码是如何支持各种不同场景的，加深对代码的理解。代码「阅读」覆盖率在第三个阶段会有一定的帮助。
所谓的代码「阅读」覆盖率，和代码测试覆盖率概念类似，后者统计的是运行测试时哪些代码被运行过，所占比例是多少，前者统计的则是哪些行代码已经理解了，哪些还不理解。通过阅读覆盖率的统计，我们能更好衡量对代码库的了解程度，增加我们深入阅读代码的乐趣。
为了实现阅读覆盖率的统计，我开发了一个简陋的浏览器插件，主要有以下功能：
功能一：基于 github，支持在 github 代码页面中标记哪些代码已经理解，效果如下图所示：
直接借助 github 代码页面来显示代码理解情况，直接扩展 github 自带的菜单，增加标记功能 （图中的 mark as read 和 mark as unread 菜单项），这样能够减少一些工作量。
功能二：统计代码阅读覆盖率
效果如下所示：
在文件列表和代码界面显示百分比。
目前插件还很简陋，不过实现方式很简单，就不分享代码了，感兴趣的同学可以自己试着开发一个。
小结，阅读学习开源代码是一种比较硬核的游戏，增加阅读覆盖率的统计，是为了给这个硬核游戏添加一些可视化元素，就像塞尔达荒野之息里的地图，你能通过它看到自己探索了哪些神庙。这类手段可以延长游戏成就带来的快感，每次当我理解了一些代码后去把它们标记出来，还是很开心的，每次对代码渐渐失去兴趣时，看到统计的百分比还比较低，就又有了研究的动力。</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>文章 on ATTS</title>
    <link>https://codenow.me/articles/</link>
    <description>Recent content in 文章 on ATTS</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 15 Mar 2019 07:28:29 +0000</lastBuildDate>
    
	<atom:link href="https://codenow.me/articles/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>Shell　入门 03</title>
      <link>https://codenow.me/articles/learning_the_shell_03/</link>
      <pubDate>Mon, 20 May 2019 00:01:40 +0900</pubDate>
      
      <guid>https://codenow.me/articles/learning_the_shell_03/</guid>
      <description>变量  变量包括
  变量名 变量值   本地变量
  在当前系统某个环境才生效的变量，作用范围小。 包括普通变量和命令变量。   普通变量定义方式
  变量名=变量值（变量值必须是一个整体，中间无特殊字符，=两边无空格） 变量名=&amp;lsquo;变量值&amp;rsquo;（看到什么输出什么） 变量名=&amp;ldquo;变量值&amp;rdquo;（变量值范围内有可以解析的变量 A，将 A 的结果和其余内容组合成整体重新赋值给变量 B）  注意：数字一般不加引号，其它默认加双引号。
 命令变量定义方式
  变量名=命令 变量名=$(命令)  执行流程：
 执行反引号或者 $() 里的命令 将命令执行后的结果赋值给新的变量   全局变量
  当前 Shell 以及其派生出来的子 Shell 中都有效的变量。   全局变量定义方式
  变量=值， export 变量 export 变量=值  查看全局变量
env   查看变量
  $变量名 &amp;rdquo;$变量名&amp;rdquo; ${变量名} &amp;rdquo;${变量名}&amp;rdquo;   取消变量</description>
    </item>
    
    <item>
      <title>Django同时支持http/https</title>
      <link>https://codenow.me/articles/django_support_https/</link>
      <pubDate>Sun, 12 May 2019 22:11:42 +0800</pubDate>
      
      <guid>https://codenow.me/articles/django_support_https/</guid>
      <description>一、django中的HTTPS HTTPS在web应用中与web服务器有关，比如搭建nginx+django应用，通过反向代理https和http请求重定向到django的http请求上，https证书在web服务器上配置，与django应用无关。当反向代理也是走https请求时，django则需要通过插件使django可支持https。
二、 django中的SECURE_SSL_REDIRECT配置 在settings.py中添加SECURE_SSL_REDIRECT = True,默认下配置为SECURE_SSL_REDIRECT = False
1. 设置SECURE_SSL_REDIRECT = True 此时在浏览器发出http请求时django会重定向到https上。
以 $ python manage.py runserver启动应用，发出http请求后django后台日志如下： &amp;ldquo;GET / HTTP/1.1&amp;rdquo; 301 0 Self-signed SSL certificates are being blocked:Fix this by turning off &amp;lsquo;SSL certificate verification&amp;rsquo; in Settings &amp;gt; General&amp;hellip;
但此时web应用是不支持https的，报错如下 You&amp;rsquo;re accessing the development server over HTTPS, but it only supports HTTP
2. 设置SECURE_SSL_REDIRECT = False 此时http请求不会跳转到https,http此时django能正确访问。如果直接请求HTTPS时会报错如下： You&amp;rsquo;re accessing the development server over HTTPS, but it only supports HTTP.</description>
    </item>
    
    <item>
      <title>Python Namedtuple 源码分析</title>
      <link>https://codenow.me/articles/python-namedtuple/</link>
      <pubDate>Sun, 12 May 2019 21:42:13 +0800</pubDate>
      
      <guid>https://codenow.me/articles/python-namedtuple/</guid>
      <description>namedtuple 是一个简化 tuple 操作的工厂函数，对于普通元组我们在访问上只能通过游标的访问，在表现力上有时候比不上对象。
命名的元组实例没有每个实例的字典，因此它们是轻量级的，并且不需要比常规元组更多的内存。
假如想计算两个点之间的距离根据定义：
需要两个点的 x、y 坐标，我们可以直接使用元组表示 p1 和 p2 点
&amp;gt;&amp;gt;&amp;gt; import math &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; p1, p2 = (1, 2), (2, 3) &amp;gt;&amp;gt;&amp;gt; s = math.sqrt((p1[0] - p2[0])**2 + (p1[1] - p2[1])**2) &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; print(s) 1.4142135623730951 &amp;gt;&amp;gt;&amp;gt; 对于 p1 点的 x 坐标使用 p1[0] 表示，对阅读上有一定的困扰，如果可以使用 p1.x 就语义清晰了。
这个场景就是 namedtuple 的典型应用，让字段具有名字，使用 namedtuple 重写上面例子
&amp;gt;&amp;gt;&amp;gt; import collections &amp;gt;&amp;gt;&amp;gt; import math &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; Point = collections.namedtuple(&amp;#39;Point&amp;#39;, [&amp;#39;x&amp;#39;, &amp;#39;y&amp;#39;]) &amp;gt;&amp;gt;&amp;gt; p1, p2 = Point(1, 2), Point(2, 3) &amp;gt;&amp;gt;&amp;gt; &amp;gt;&amp;gt;&amp;gt; s = math.</description>
    </item>
    
    <item>
      <title>Shell　入门 02</title>
      <link>https://codenow.me/articles/learning_the_shell_02/</link>
      <pubDate>Sat, 11 May 2019 17:35:27 +0900</pubDate>
      
      <guid>https://codenow.me/articles/learning_the_shell_02/</guid>
      <description>Shell 脚本基本知识  脚本常见编辑器：
 vi vim
 脚本命名：
 见名知义
 脚本执行方式
 # 推荐 - bin/bash /path/to/script-name 或 bash /path/to/script-name # 文件有可执行权限，在当前路径下执行脚本 - /path/to/script-name 或 ./script-name # 注意 `.` 符号 - source script-name 或 . script-name    说明：
  ☆☆☆ 当脚本文件本身没有`可执行权限`或脚本首行没有命令解释器时使用的方法时，推荐用 bash 执行。 会开启新进程，不能共享环境，不能共享变量 ☆☆☆ 当脚本文件具有可执行权限时使用。 会开启新进程，不能共享环境，不能共享变量 ☆☆ 使用 source 或者 `.` 加载脚本文件，使脚本环境与当前用户环境一致， 不会新开进程，能与 shell 窗口共享进程，共享环境，共享变量   脚本开发规范
 文件后缀是 .sh  脚本文件首行是且必须是脚本解释器，一般是 #！ /bin/bash  脚本解释器后要有脚本基本信息，尽量用英文注释。 常见注释信息包括脚本名字、功能描述、脚本版本、作者和联系方式等  脚本内容执行：由上至下，依次执行  代码书写优秀习惯</description>
    </item>
    
    <item>
      <title>如何使用Python过滤emoji</title>
      <link>https://codenow.me/articles/how_to_use_python_filter_emoji/</link>
      <pubDate>Mon, 06 May 2019 00:32:31 +0800</pubDate>
      
      <guid>https://codenow.me/articles/how_to_use_python_filter_emoji/</guid>
      <description> 参考博客：http://my.oschina.net/jiemachina/blog/189460
1. 将emoji表情替换为指定字符串 import re def filter_emoji(desstr, restr=&amp;#39;&amp;#39;): &amp;#34;&amp;#34;&amp;#34;过滤表情&amp;#34;&amp;#34;&amp;#34; try: # python UCS-4 build的处理方式 highpoints = re.compile(u&amp;#39;[\U00010000-\U0010ffff]&amp;#39;) except re.error: # python UCS-2 build的处理方式 highpoints = re.compile(u&amp;#39;[\uD800-\uDBFF][\uDC00-\uDFFF]&amp;#39;) return highpoints.sub(restr, desstr) 2. 把字符串变成表情 import HTMLParser def str_2_emoji(emoji_str): &amp;#34;&amp;#34;&amp;#34;把字符串转换为表情&amp;#34;&amp;#34;&amp;#34; if not emoji_str: return emoji_str h = HTMLParser.HTMLParser() emoji_str = h.unescape(h.unescape(emoji_str)) # 匹配u&amp;#34;\U0001f61c&amp;#34;和u&amp;#34;\u274c&amp;#34;这种表情的字符串 co = re.compile(r&amp;#34;u[\&amp;#39;\&amp;#34;]\\[Uu]([\w\&amp;#34;]{9}|[\w\&amp;#34;]{5})&amp;#34;) pos_list=[] result=emoji_str # 先找位置 for m in co.finditer(emoji_str): pos_list.append((m.start(),m.end())) # 根据位置拼接替换 for pos in range(len(pos_list)): if pos == 0: result=emoji_str[0:pos_list[0][0]] else: result=result+emoji_str[pos_list[pos-1][1]:pos_list[pos][0]] result = result +eval(emoji_str[pos_list[pos][0]:pos_list[pos][1]]) if pos==len(pos_list)-1: result=result+emoji_str[pos_list[pos][1]:len(emoji_str)] return result</description>
    </item>
    
    <item>
      <title>JAVA初始化零碎知识点整理</title>
      <link>https://codenow.me/articles/java_initialization/</link>
      <pubDate>Sun, 05 May 2019 14:19:45 +0900</pubDate>
      
      <guid>https://codenow.me/articles/java_initialization/</guid>
      <description>近期在学习Java语言，整理了部分初始化内容的知识点
区分重载方法 当有多个方法拥有相同名字时，可以为每个方法设置不同的参数类型列表，从而实现方法的区分。
public class Test{ static f(String s, int i){ System.out.println(&amp;#34;String:&amp;#34; + s + &amp;#34;, int:&amp;#34; + i); } static f(String s, int i, int j){ System.out.println(&amp;#34;String:&amp;#34; + s + &amp;#34;, int:&amp;#34; + i + &amp;#34;, int:&amp;#34;+ j); } } 同样可以通过改变参数顺序重载方法：
public class Test{ static f(String s, int i){ System.out.println(&amp;#34;String:&amp;#34; + s + &amp;#34;, int:&amp;#34; + i); } static f(int i, String s){ System.out.println(&amp;#34;String:&amp;#34; + s + &amp;#34;, int:&amp;#34; + i); } } this关键字  this：调用对象的引用</description>
    </item>
    
    <item>
      <title>Shell　入门 01</title>
      <link>https://codenow.me/articles/learning_the_shell_01/</link>
      <pubDate>Sun, 05 May 2019 13:51:10 +0900</pubDate>
      
      <guid>https://codenow.me/articles/learning_the_shell_01/</guid>
      <description>Shell 的定义  一个命令解释器 位于操作系统和应用程序之间  Shell 的作用 shell 负责把应用程序的输入命令信息解释给操作系统，将操作系统指令处理后的结果解释给应用程序。
Shell 的分类  图形界面式  桌面  命令行式
 windows 系统 (cmd.exe)
 Linux 系统 (sh, bash, zsh&amp;hellip;)
   查看系统 shell 信息 echo $SHELL  查看系统支持的 shell cat /etc/shells  Shell 的使用  手工方式  逐行输入命令，逐行进行确认执行
 脚本方式  把执行命令写进脚本文件中，通过执行脚本达到执行效果
  shell 脚本定义 当可执行的 Linux 命令或语句不在命令行状态下执行，而是通过一个文件执行时，我们称文件为shell 脚本。
shell 脚本示范  创建一个脚本   vim temp.sh  脚本内容</description>
    </item>
    
    <item>
      <title>Sentry Pushbear</title>
      <link>https://codenow.me/articles/sentry-pushbear/</link>
      <pubDate>Sat, 04 May 2019 23:19:21 +0800</pubDate>
      
      <guid>https://codenow.me/articles/sentry-pushbear/</guid>
      <description>上周写了一下 sentry 可以通过 webhook 发送错误日志给微信，但是需要自己额外搭一个服务，虽然可定制化确实强，但还是有点麻烦
于是五一期间给 sentry 写了个插件，简单安装之后，只需要填上 pushbear 的 SendKey，就可以直接在微信上接收错误提醒啦~
效果如下：
(这里缺上图，后面补)
目前我配了这四个参数：project, culprit, message 和 tags。一般已经可以快速定位错误项目和位置了，至于具体的 trace，可以点击 message 直接进入 sentry 查看
安装也超简单：
如果 sentry 是 docker 安装的  在 onpremise/requirements.txt 里加上一行 sentry-pushbear docker-compose build: 拉取插件代码 docker-compose run --rm web upgrade: 更新 web 服务，如果插件有问题这里会报错 docker-compose up -d: 重启 sentry，插件生效  如果 sentry 是 python 安装的  pip install sentry-pushbear 重启 sentry  使用 pushbear 服务 在项目配置页，也就是 project-&amp;gt;{project}-&amp;gt;settings 页面里，点击 All integration(or plugins or Legacy Integrations) 页面，可以找到 PushBear Notifications 插件</description>
    </item>
    
    <item>
      <title>数据库到底要不要外键</title>
      <link>https://codenow.me/articles/db-without-fk/</link>
      <pubDate>Mon, 29 Apr 2019 00:06:39 +0800</pubDate>
      
      <guid>https://codenow.me/articles/db-without-fk/</guid>
      <description>数据库的本质是存储数据，在这个之上还要维护数据的完整性。在维护完整性数据库提供几种方法，一种是事务，一种是外键 FK。这两种方式是分别处理两种情况，事务处理的是多个表中记录的原子性，FK 是处理多条有关系的记录。
举个外键例子来说，假如有一个资源管理系统，你申请了许多资源，有电脑、账号、书籍、笔记本等好多东西，在你离职时候，这些记录需要全部删除，同时你的账号也要从这个系统中删除。这时候如果存在外键，user 表中的 id 字段关联了各种的资源 id，这时候需要一条 SQL 就可以删除这些记录。
所以这么看外键貌似很有用，真实情况是真的很有用。但是我们从给一个角度来看，一条 SQL 需要级联多个表的操作，在 DB 引擎中可能同时需要多个行锁或者表锁，来保证完整性。同时还会会涉及到 IO 问题，我们都知道 IO 的随机读写其实是比较慢的，在访问频繁的的时候数据库往往不足以支撑那么大量的请求。
一般这种观点的人会给出以下几个理由：
 性能好 修改开放，易于维护  坚持使用外键的人也有几个理由：
 数据完整性 表结构清晰 约束性好  无论怎么看都貌似很有道理，事实就是都对，但是要看在什么情况下使用，要从架构层面上取长补短。假如我们使用了无外键的设计，那么就要从架构补足缺点。举个例子来说，无外键设计一般会上移逻辑层到程序中，由程序要维护数据完整性，随着程序重启崩溃总是会出现一些游离数据。这些游离数据对系统究竟没有影响就很关键了，如果说这些游离数据不会影响系统正常运行，那么无外键的设计就很成功。典型的就是只需要根据 id 来获取某些数据，而不是通过某些条件来范围查询数据。
这个其实很好理解，对于只用 id 获取的数据我只要保证这个 id 有没有没有被删除就 ok 了，那些关联的数据在这个 id 被删除以后就再也无法被找到了。
如果说你正在做的是一个账号相关的系统，往往和账号相关的数据要求的完整性都很高，无法容忍出现游离数据，那么你只能使用外键来维护这种关系，虽然说上移到程序也能做，但是总不如数据库来的彻底。
对于访问量大的表来说，一般会对这个表分片处理，分片的原理是根据某个字段把数据分散到多个片当中，这时候外键就无法起作用了，对于互联网公司来说分片做的都很多，外键设计变得越来越少。精明的架构师会用各种方法来补足无外键的缺点。
总结一下，关于是不是要外键的回答可以肯定的是，要和不要都可以。具体要看业务如何拆分，数据容忍度有多高，以及架构师是否精明。如果以上没有一个，那么还是老老实实使用外键设计。</description>
    </item>
    
    <item>
      <title>Sentry Wechat</title>
      <link>https://codenow.me/articles/sentry-wechat/</link>
      <pubDate>Sun, 28 Apr 2019 23:49:25 +0800</pubDate>
      
      <guid>https://codenow.me/articles/sentry-wechat/</guid>
      <description>这周给 sentry 监控多做了一个发送途径
目前我常用的 notification 途径有： 1. 邮件 2. slack 3. 微信
对 sentry 来说，email 和 slack 已经是内置支持的了，甚至 slack 还支持对收到的消息进行操作，比如 assign 给某人，或者标记 resolved
对微信的推送没有显式的支持，但 sentry 提供了 webhook，可以用这种方式来曲线救国
因此需要两个东西： 1. 从 sentry 接收消息的服务 2. 能推送微信消息的服务
对于第二点，现在有几个十分方便的解决方式，从最开始的 server酱，到升级版的 PushBear，使用体验都十分丝滑柔顺，也真的推荐大家前去实验
那么第一点要怎么做？
sentry 提供了官方的 webhook 工具：https://github.com/getsentry/webhook
当然如果使用 docker 安装，或者版本够高的话，这个插件已经内置了。也就是填写一个 url，然后设定规则（比如默认规则是当某个 issue 第一次被触发时），那么当满足这个规则时，sentry 就会往这个链接发一个请求，同时在 json 里带上以下数据：
{ &#39;project_name&#39;: &#39;woko&#39;, &#39;message&#39;: &#39;This is an example Python exception&#39;, &#39;id&#39;: &#39;1002921092&#39;, &#39;culprit&#39;: &#39;raven.scripts.runner in main&#39;, &#39;project_slug&#39;: &#39;woko&#39;, &#39;url&#39;: &#39;https://sentry.</description>
    </item>
    
    <item>
      <title>Tmux 快捷键</title>
      <link>https://codenow.me/articles/tmux_hotkey/</link>
      <pubDate>Sun, 28 Apr 2019 23:13:11 +0900</pubDate>
      
      <guid>https://codenow.me/articles/tmux_hotkey/</guid>
      <description>启动 tmux： tmux
 创建新命名会话和命名窗口： tmux new -s name -n name
 恢复会话： tmux at [-t 会话名]
 会话后台运行 prefix d
 列出所有会话： tmux ls
 关闭会话： tmux kill-session -t 会话名
 关闭所有会话： tmux ls | grep : | cut -d. -f1 | awk &amp;lsquo;{print substr($1, 0, length($1)-1)}&amp;rsquo; | xargs kill
 触发 tmux： ctr+b
 新建窗口： prefix c
 切换窗口： alt+窗口号（1，2，3）
 退出窗口 prefix x
 窗口重命名 prefix ，</description>
    </item>
    
    <item>
      <title>自定义 eslint 规则</title>
      <link>https://codenow.me/articles/custom-rule-for-eslint/</link>
      <pubDate>Sun, 28 Apr 2019 22:10:12 +0800</pubDate>
      
      <guid>https://codenow.me/articles/custom-rule-for-eslint/</guid>
      <description>本文记录一下如何开发基于 estlint 的自定义检查规则。开发规则的官方文档：文档链接。如何在本地测试规则的方法，请参考 这篇文章。
下面是一个实际的例子，用这个规则，可以检测下面这种代码：
if (a.b &amp;amp;&amp;amp; a.b.c &amp;amp;&amp;amp; a.b.c.d &amp;amp;&amp;amp; a.b.c.d) { // send some ajax request }  自定义规则代码如下：
// 逻辑表达式是一颗二叉树，对其进行 flatten 操作 // 比如 a &amp;amp;&amp;amp; b &amp;amp;&amp;amp; c &amp;amp;&amp;amp; d ，flatten 的结果 [a, b, c, d] function flattenLogicalExpression(node) { if (node.operator !== &amp;#39;&amp;amp;&amp;amp;&amp;#39;) { return [node] } let ret = [] if (node.left.type !== &amp;#39;LogicalExpression&amp;#39;) { ret.push(node.left) } else { ret = ret.concat(flattenLogicalExpression(node.left)) } if (node.</description>
    </item>
    
    <item>
      <title>Dockerfile常见命令(一)</title>
      <link>https://codenow.me/articles/dockerfile_commands1/</link>
      <pubDate>Fri, 26 Apr 2019 18:51:05 +0800</pubDate>
      
      <guid>https://codenow.me/articles/dockerfile_commands1/</guid>
      <description>FROM  格式：
FROM&amp;lt;image&amp;gt;&amp;#91;AS &amp;lt;name&amp;gt;&amp;#93;
FROM&amp;lt;image&amp;gt;&amp;#91;: &amp;lt;tag&amp;gt;&amp;#93; &amp;#91;AS &amp;lt;name&amp;gt;&amp;#93;
FROM&amp;lt;image&amp;gt;&amp;#91;@ &amp;lt;digest&amp;gt;&amp;#93; &amp;#91;AS &amp;lt;name&amp;gt;&amp;#93;
说明：
FROM指令为后续指令创建一个基础镜像。所以所有的Dockerfile应该都是从FROM指令开始。初始化的镜像可以是任意合法的镜像。
如果初始化的镜像在本地不存在，则会从公告仓库中获取镜像。
 RUN  格式：
RUN &amp;lt;command&amp;gt; RUN &amp;#91;&amp;ldquo;executable&amp;rdquo;, &amp;ldquo;param1&amp;rdquo;, &amp;ldquo;param2&amp;rdquo;&amp;#93;
说明：
RUN指令会在当前镜像上生成新层，并在新层钟执行命令和提交结果。生成的新的镜像将用于下一步的Dockerfile。
exec表单(第二种格式)被解析为JSON数组，这意味着必须使用双引号，不能使用单引号。
&amp;ldquo;executable&amp;rdquo;中涉及到的路径必须转义反斜杠(\)。
 CMD  格式：
CMD &amp;#91;&amp;ldquo;executable&amp;rdquo;, &amp;ldquo;param1&amp;rdquo;, &amp;ldquo;param2&amp;rdquo;&amp;#93; (执行形式，这是首选形式)
CMD &amp;#91;&amp;ldquo;param1&amp;rdquo;, &amp;ldquo;param2&amp;rdquo;&amp;#93; (作为ENTRYPOINT的默认参数)
CMD command param1 param2 (shell形式)
说明：
Dockerfile中只能有一个CMD指令，如果使用了多个，则只有在最后的CMD会生效。
如果CMD用于为ENTRYPOINT指令提供默认参数，则应使用JSON数组格式指定CMD和ENTRYPOINT指令。
 LABEL  格式：
LABEL &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; &amp;lt;key&amp;gt;=&amp;lt;value&amp;gt; &amp;hellip;
说明：
LABEL指令将元数据添加到图像，LABEL使用键值对进行传值。
镜像可以有多个标签，要指定多个标签，Docker建议LABEL尽可能将标签组合到单个指令中。如果使用多个LABEL，每条指令会生成一个新的图层，从而导致镜像效率低下。
 EXPOSE  格式：
EXPOSE &amp;lt;port&amp;gt; &amp;#91;&amp;lt;port&amp;gt; /&amp;lt;protocol&amp;gt;&amp;hellip;&amp;#93;</description>
    </item>
    
    <item>
      <title>Python_i18n</title>
      <link>https://codenow.me/articles/python_i18n/</link>
      <pubDate>Sun, 21 Apr 2019 22:55:21 +0800</pubDate>
      
      <guid>https://codenow.me/articles/python_i18n/</guid>
      <description>这周有一些 API 需要做国际化，于是看了一下通用的解决方案
GUN 国际化通用方法: gettext 通用的解决方案是，使用 gettext 工具，先将源码中的字符串提取至 .pot 文件中，再复制成各个 .po 文件并填充相应的语言，填充完毕后，再编译成 .mo 文件。
读取的时候，从一个 .mo 文件里得到的内容会转换成一个简单的 hash map(python 中就是单纯的 dict)，使用时根据语言和原始字符串到这里查找，即可得到相应的“翻译后的字符串”并返回。
我们可以看一下前段时间刚刚上线的 python 官方简中文档，这是术语表的 .po 文件链接：https://github.com/python/python-docs-zh-cn/blob/3.7/glossary.po
参照这个图片，可以看到， .po 文件里会把原文里的每个字符串，都这样对照着给一个翻译
说到这里我们插播一下，python 中文文档翻译进度已经达到 30% 了，想参与翻译吗？参照我这个帖子开动吧，或者直接留言，我拉你进翻译群~
说回到国际化，gettext 是一个 GNU 工具，各种语言对它都有支持，官方文档在这里：https://www.gnu.org/software/gettext/manual/gettext.html
在 shell 下它一共提供三个命令： 1. xgettext: 从源文件中提取 .pot 文件 2. msginit: 将 .pot 准备成对应语言的 .po 文件 3. msgfmt: 将 .po 文件编译成 .mo 文件
具体的用法就不详细说了，搜一下有很多，我们这里说一下 python 中对其的实现
python 中内置了一个 gettext 包，其实是为 GUN gettext 提供一个 python 接口，使用时只要指定好语言以及 .</description>
    </item>
    
    <item>
      <title>MySQL 排序机制</title>
      <link>https://codenow.me/articles/how-to-orderby-in-mysql/</link>
      <pubDate>Sun, 21 Apr 2019 21:58:20 +0800</pubDate>
      
      <guid>https://codenow.me/articles/how-to-orderby-in-mysql/</guid>
      <description>在 MySQL 中经常使用 Order by 对数据进行排序，其实排序这个行为是比较消耗 IO 的过程，有时候需要回表多次才可以完成排序，所以在任何时候都需要对排序的原理要心知肚明。
在 MySQL 中排序按照是否使用外部存储可以分为，内存排序和外部排序两种。根据排序所需的字段可以分成 rowid 排序和全字段排序两种。
在 MySQL 执行排序的时候会分配一块内存 sort_buffer，MySQL 把需要排序的字段放入这个 sort_buffer 中，让，后在 sort_buffer 执行排序的过程，如果 sort_buffer 大小不够，就要使用外部存储。
一般来说 sort_buffer_size 的大小取决于排序的是使用快排（内存排序）还是归并排序（外部排序）。
以上的排序过程都是使用全字段进行排序的，但是如果 sort_buffer 不足以存放所有排序字段，那么这时候就需要用到 rowid 排序。
对于 rowid 排序支取 id 和需要排序的字段放入 sort_buffer 中，在 sort_buffer 开始对字段进行排序。根据排序完成后的 id 再回表找到其他字段组合成结果集返回。
对于 rowid 排序和全字段排序最大差别在于多一次回表的过程，这也是一次 io 消耗过程（不一定是随机读过程）。同时扫描次数 rowid 会多余全字段排序 n 行，这个 n 就是第二次回表过程根据 id 找到的行的数量。
对于 MySQL 来说如果内存够，就要多利用内存，尽量减少磁盘访问，只有分配的内存不够用的时候才会使用 rowid 排序。
那么，这个过程如何优化？我们可以发现优化的地方有两个，一个是排序所消耗的时间，一个是回表再次读取的时间。所以优化就可以根据这两个来。
对于回表这个操作经常和数据量有关系没有什么好办法，一种比较常用的方法就是建立复合索引以减少排序所耗费的时间。如果再 order by 时候字段满足最左匹配原则，那么这时候第一次从表加载到 sort_buffer 中本身就有序的，那么这时候可以直接当做结果返回了，就不需要排序了。
最后，使用 explain 可以分析 SQL 的排序方式：</description>
    </item>
    
    <item>
      <title>TiDB 源码学习：列裁剪</title>
      <link>https://codenow.me/articles/tidb-outer-join-elimination-and-column-pruning/</link>
      <pubDate>Sun, 21 Apr 2019 21:51:04 +0800</pubDate>
      
      <guid>https://codenow.me/articles/tidb-outer-join-elimination-and-column-pruning/</guid>
      <description>今天整理 TiDB 的一种常见优化手段：列裁剪 (column pruning)
列裁剪是很常见的一种优化手段，除了能够降低网络开销以外，也能够降低数据库的内存开销和 cpu 开销。比如下面这个查询：
select t1.id from t1, t2 where t1.id == t2.t1_id where t2.state = 1; 这个查询比较极端，t2 表在 join 之后，没有任何一列会再需要被使用。假如 t2 表里有十多个字段，而查询没有做列裁剪的话。那这十几个字段要在在整个查询树上流动，内存开销就得大出好几倍。
代码中，是通过递归调用各个 LogicalPlan 子类的 PruneColumns 来完成列裁剪的，PruneColumns 方法会代用上层节点要求使用的列信息，子节点根据上层节点要使用的列信息以及自己要使用的列信息（比如：上个例子中 的 t2.t1_id 和 t2.state ，上层节点不会使用但是连接过程要使用）来计算哪些列可以被裁剪掉。
Join 的 PruneColumns 方法
func (p *LogicalJoin) extractUsedCols(parentUsedCols []*expression.Column) (leftCols []*expression.Column, rightCols []*expression.Column) { for _, eqCond := range p.EqualConditions { parentUsedCols = append(parentUsedCols, expression.ExtractColumns(eqCond)...) } for _, leftCond := range p.LeftConditions { parentUsedCols = append(parentUsedCols, expression.</description>
    </item>
    
    <item>
      <title>Docker的进程</title>
      <link>https://codenow.me/articles/docker_process/</link>
      <pubDate>Sun, 21 Apr 2019 20:55:18 +0800</pubDate>
      
      <guid>https://codenow.me/articles/docker_process/</guid>
      <description>1. 查看Docker进程 在Linux系统中，启动Docker服务，会看到如下进程：
CentOS7： [root@lvs-webserver2 ~]# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES c8a999e1b510 ubuntu &amp;#34;/bin/bash&amp;#34; 34 seconds ago Up 32 seconds ubuntu [root@lvs-webserver2 ~]# [root@lvs-webserver2 ~]# ps -ef|grep docker|grep -v grep root 40362 1 1 18:14 ? 00:00:08 /usr/bin/dockerd root 40373 40362 2 18:14 ? 00:00:14 docker-containerd --config /var/run/docker/containerd/containerd.toml root 40758 40373 0 18:23 ? 00:00:00 docker-containerd-shim -namespace moby -workdir /var/lib/docker/containerd/daemon/io.containerd.runtime.v1.linux/moby/c8a999e1b510abc2136384742f9ce8fa082d297e83af07d50c8b0d8f47254609 -address /var/run/docker/containerd/docker-containerd.sock -containerd-binary /usr/bin/docker-containerd -runtime-root /var/run/docker/runtime-runcUbuntu18 root@lvs-master:/var/run# docker ps -a CONTAINER ID IMAGE COMMAND CREATED STATUS PORTS NAMES e96ce4c8c256 redisexec &amp;#34;/usr/bin/redis-serv…&amp;#34; 11 days ago Up 9 minutes 6379/tcp redisexec root@lvs-master:/var/run# root@lvs-master:/var/run# ps -ef|grep docker |grep -v grep root 1039 1 0 18:24 ?</description>
    </item>
    
    <item>
      <title>漫谈死锁</title>
      <link>https://codenow.me/articles/about_mysql_locks_2/</link>
      <pubDate>Sun, 21 Apr 2019 18:18:29 +0900</pubDate>
      
      <guid>https://codenow.me/articles/about_mysql_locks_2/</guid>
      <description>作者：杨一
原链接： 漫谈死锁
 一、前言 死锁是每个 MySQL DBA 都会遇到的技术问题，本文自己针对死锁学习的一个总结，了解死锁是什么，MySQL 如何检测死锁，处理死锁，死锁的案例，如何避免死锁。
二、死锁 死锁是并发系统中常见的问题，同样也会出现在 Innodb 系统中。当两个及以上的事务，双方都在等待对方释放已经持有的锁或者因为加锁顺序不一致造成循环等待锁资源，就会出现&amp;rdquo;死锁&amp;rdquo;。
举例来说 A 事务持有 x1锁 ，申请 x2 锁，B 事务持有 x2 锁，申请 x1 锁。A 和 B 事务持有锁并且申请对方持有的锁进入循环等待，就造成死锁。
从死锁的定义来看，MySQL 出现死锁的几个要素：
a 两个或者两个以上事务。 b 每个事务都已经持有锁并且申请新的锁。 c 锁资源同时只能被同一个事务持有或者不兼容。 d 事务之间因为持有锁和申请锁导致了循环等待。
三、MySQL 的死锁机制 死锁机制包含两部分：检测和处理。 把事务等待列表和锁等待信息列表通过事务信息进行 wait-for graph 检测，如果发现有闭环，则回滚 undo log 量少的事务；死锁检测本身也会算检测本身所需要的成本，以便应对检测超时导致的意外情况。 3.1 死锁检测 当 InnoDB 事务尝试获取(请求)加一个锁，并且需要等待时，InnoDB 会进行死锁检测。正常的流程如下:
 InnoDB 的初始化一个事务，当事务尝试申请加一个锁，并且需要等待时 (wait_lock)，innodb 会开始进行死锁检测 (deadlock_mark) 进入到 lock_deadlock_check_and_resolve() 函数进行检测死锁和解决死锁 检测死锁过程中，是有计数器来进行限制的，在等待 wait-for graph 检测过程中遇到超时或者超过阈值，则停止检测。 死锁检测的逻辑之一是等待图的处理过程，如果通过锁的信息和事务等待链构造出一个图，如果图中出现回路，就认为发生了死锁。 死锁的回滚，内部代码的处理逻辑之一是比较 undo 的数量，回滚 undo 数量少的事务。  3.</description>
    </item>
    
    <item>
      <title>Doker核心概念-镜像、容器和仓库</title>
      <link>https://codenow.me/articles/the_image_container_repository_in_docker/</link>
      <pubDate>Sat, 20 Apr 2019 15:55:09 +0800</pubDate>
      
      <guid>https://codenow.me/articles/the_image_container_repository_in_docker/</guid>
      <description>Docker镜像 Docker镜像类似于虚拟机镜像，可以将它理解为一个只读模板。 例如，一个镜像包含一个基本的操作系统环境，里面仅安装了Apache应用程序(或用户需要的其他软件)。可以把它称为一个Apache镜像。 镜像是创建Docker容器的清楚。通过版本管理和增量的文件系统，Docker提供了一套十分简单的机制来创建和更新现有的镜像，用户甚至可以从网上下载一个已经做好的应用镜像，并直接使用。
Docker容器 Docker容器类似于一个轻量级的沙盒，Docker利用容器来运行和隔离应用。 容器时从镜像创建的应用运行实例。他可以启动、停止、删除，而这些容器都是彼此相互隔离、互补可见的。 可以把容器看作一个简易版的Linux系统环境(包括root用户系统，进程空间，用户空间和网络空间等)以及运行在其中的应用程序打包而成的盒子。
Docker仓库 Docker仓库类似于代码仓库，是Docker集中存放镜像文件的场所。 有时候我们会将Docker仓库和仓库注册服务器(Registry)混为一谈，并不严格区分。实际上，仓库注册服务器是存放仓库的地方，其上往往存放着多个仓库。每个仓库集中存放某一类镜像，往往包括多个镜像文件，通过不同的标签(tag)来进行区分。例如存放Ubuntu操作系统镜像的仓库，被称为Ubuntu仓库，其中可能包括不同版本的镜像。
根据所存储的镜像公开与否，Docker仓库可以分为公开仓库和私有仓库两种形式。目前，最大的公开仓库是官方提供的Docker Hub，其中存放着数量庞大的镜像供用户下载。国内不少云服务提供商(如腾讯云，阿里云等)也提供了仓库的本地源，可以提供稳定的国内访问。 当然，用户如果不希望公开分享自己的镜像文件，Docker也支持用户在本地网络内创建一个只能自己访问的私有仓库。 当用户创建了自己的镜像之后，就可以使用push命令将它上传到指定的公有或者私有仓库。这样用户下次在另一台机器上使用该镜像时，只需要将其从仓库上pull下来即可。
镜像和容器的区别： 镜像是一个只读系统，在这个只读系统中存在很多只读层，它们按照层次顺序堆叠在一起，中间使用指针连接起来(指针指向下一层)。统一的文件系统将多层只读层统一起来，所以看起来会是一个整体。 容器在镜像的上层添加了一层可读可写层。通过该层，可以经过系统进行写入操作。初次之外，容器几乎是与镜像一样的。</description>
    </item>
    
    <item>
      <title>Sentry Raven vs Sentry_sdk</title>
      <link>https://codenow.me/articles/sentry-raven-vs-sentry_sdk/</link>
      <pubDate>Mon, 15 Apr 2019 00:04:31 +0800</pubDate>
      
      <guid>https://codenow.me/articles/sentry-raven-vs-sentry_sdk/</guid>
      <description>上周写了 Sentry 的 Python SDK raven 包的工作原理，但这周发现 Sentry Team 把 SDK 又给重构了一版，现在叫做 New Unified Version: sentry-sdk。
但是更新工作没做彻底， 官网(https://docs.sentry.io) 上的文档虽然已经改成 sentry-sdk 了，但 sentry-web 服务上的各种说明还没改，而且新版 SDK 的版本号还没到 1.0(0.7.10)，raven 已经完善到 6.10.0 了
于是又读了一下这个包的代码，与之前真的大不相同了。
以下内容分两部分：
 对 SDK 的用户来说，都有哪些变化 新 SDK 在实现方式上有什么变化  新旧 SDK 变化对比 简单写了个表，功能上的区别基本就是这样了，实际使用上倒是完全感受不到什么
   对比项 raven sentry_sdk     捕捉错误的方式 flask.got_request_exception + middleware flask.got_request_exception + middleware   获取上下文等信息的方式(flask) 直接访问 flask.request，以及 sys.exc_info 和环境相关信息 使用信号 appcontext_pushed, request_started 和 sys.</description>
    </item>
    
    <item>
      <title>CGroups 控制进程资源</title>
      <link>https://codenow.me/articles/linux-cgroups/</link>
      <pubDate>Sun, 14 Apr 2019 21:53:50 +0800</pubDate>
      
      <guid>https://codenow.me/articles/linux-cgroups/</guid>
      <description>cgroups 是 Linux 内核中的一个功能，用来限制、控制分离一个进程的资源，比如 CPU、内存、IO 等。
cgroups 是由一组子系统构成，每种子系统即时一种资源，目前可使用的资源如下：
 cpu：限制 cpu 的使用率 cpuacct：cpu 的统计报告 cpuset：分配 cpu memory：分配 mem 的使用量 blkio：限制块设备的 io devices：能够访问的设备 net_cls：控制网络数据的访问 net_prio：网络流量包的优先级 freezer：pause 或者 resume 进程 ns：控制 namespace 的访问  cgroups 中有个 hierarchy 的概念，意思一组 cgroup 是一棵树，cgroup2 可以挂在 cgroup 1 上，这样可以从 cgroup1 中继承设置。
所以 process、subsystem、hierarchy 存在一些关系。
 一个 subsystem 只能附加到一个 hierarchy 一个 hierarchy 可以附加到多个 subsystem 中 一个 process 可以作为多个 cgroups 成员，但是要在不同的 hierarchy 中 fork 出的子进程默认和父进程使用一个 cgroups，但是可以移动到其他的 cgroups 中  在 linux 中 /sys/fs/cgroup 中是 cgroups 默认的 hierarchy，可以看到目前的 subsystem</description>
    </item>
    
    <item>
      <title>Tidb 源码学习：关于 join 性能优化</title>
      <link>https://codenow.me/articles/tidb-join-performance-optimization-1/</link>
      <pubDate>Sun, 14 Apr 2019 20:41:10 +0800</pubDate>
      
      <guid>https://codenow.me/articles/tidb-join-performance-optimization-1/</guid>
      <description>最近在尝试自己写数据库查询模块，满足 http://sigmod18contest.db.in.tum.de/task.shtml 的功能要求。一边看着 TiDB 的代码，一边写… 这个过程中发现了一些 TiDB 优化点。
join reorder 每个数据库系统基本都要实现 join reorder，修改表连接的顺序，从而提高 join 的性能，比如下面这个查询：
select a.id, b.id, c.id from a, b, c where a.id = b.a_id and a.id = c.a_id; 查询要连接 a/b/c 三张表，可以先连接 a 和 b，也可以先连接 a 和 c，当然如果你想不开的话，也可以先连接 a 和 c。如果 a join b 产生的数据比 a join c 产生的数据多，那么先计算 a join c 一般性能会更好。
很多数据库在表少的时候会使用动态规划来解决这个问题，比如 这篇文章 中介绍的算法。大致思路是根据表和用来连接的条件看做是一个无环图，表是节点，筛选条件是边。要计算最优的连接顺序，就是根据这张图计算出一个 sJoin Tree，Join Tree 除叶子节点以外其他的节点都是 Join。动规的过程是将图拆分成各种子图的组合并从中找出最优组合。
下面是 TiDB 中 join reorder 的主体代码：</description>
    </item>
    
    <item>
      <title>运行shell和exec命令时，Docker进程的区别</title>
      <link>https://codenow.me/articles/docker_process_about_run_shell_and_exec/</link>
      <pubDate>Sun, 14 Apr 2019 17:55:40 +0800</pubDate>
      
      <guid>https://codenow.me/articles/docker_process_about_run_shell_and_exec/</guid>
      <description>1. 前言 Docker容器内运行的进程对于宿主机而言，是独立进程，还是Docker容器进程？
Docker容器内启动的进程全部都是宿主机上的独立进程
Docker容器内启动的进程是不是Docker进程本身要看Dockerfile的写法
比如Docker内启动redis，如果用CMD &amp;ldquo;/usr/bin/redis-server&amp;rdquo;，这是用shell启动，会先启动shell，然后再启动redis，所以不是Docker进程本身；
如果用CMD [&amp;ldquo;/usr/bin/redis-server&amp;rdquo;]，这是用exec启动，是直接启动redis，进程号为1，所以是Docker进程本身
2. shell方式 1) shell方式的Dockerfile
root@ubuntu:~# cat Dockerfile FROM ubuntu:18.04 RUN apt-get update &amp;amp;&amp;amp; apt-get -y install redis-server &amp;amp;&amp;amp; rm -rf /var/lib/apt/lists/* EXPOSE 6379 CMD &amp;#34;/usr/bin/redis-server&amp;#34; 2)shell方式创建容器
root@ubuntu:~# docker build -t redisshell -f Dockerfile . 3) shell方式创建并运行镜像
root@ubuntu:~# docker run --name redisshell redisshell 4) redisshell容器内进程
root@ubuntu:~# docker exec -it redisshell ps -ef UID PID PPID C STIME TTY TIME CMD root 1 0 0 17:36 ?</description>
    </item>
    
    <item>
      <title>Mysql 锁：灵魂七拷问</title>
      <link>https://codenow.me/articles/about_mysql_locks/</link>
      <pubDate>Sun, 14 Apr 2019 13:49:26 +0900</pubDate>
      
      <guid>https://codenow.me/articles/about_mysql_locks/</guid>
      <description>作者：柳树 on 美业 from 有赞coder
原链接： Mysql 锁：灵魂七拷问
 一、缘起 假设你想给别人说明，Mysql 里面是有锁的，你会怎么做？
大多数人，都会开两个窗口，分别起两个事务，然后 update 同一条记录，在发起第二次 update 请求时，block，这样就说明这行记录被锁住了： 二、禁锢 问题来了，貌似只有显式的开启一个事务，才会有锁，如果直接执行一条 update 语句，会不会加锁呢？
比如直接执行：
update t set c = c + 1 where id = 1; 这条语句，前面不加 begin，不显式开启事务，那么 Mysql 会不会加锁呢？
直觉告诉你，会。
但是为什么要加锁？
给你五秒钟，说出答案。
学过多线程和并发的同学，都知道下面这段代码，如果不加锁，就会有灵异事件：
i++; 开启十个线程，执行 1000 次这段代码，最后 i 有极大可能性，会小于 1000。
这时候，用 Java 的套路，加锁：
synchornize { i++; } 问题解决。
同理，对于数据库，你可以理解为 i，就是数据库里的一行记录，i++ 这段代码，就是一条 update 语句，而多线程，对应的就是数据库里的多个事务。
既然对内存中 i 的操作需要加锁，保证并发安全，那么对数据库的记录进行修改，也必须加锁。
这道理很简单，但是很多人，未曾想过。
三、释然 为什么大家都喜欢用第一部分里的例子来演示 Mysql 锁？</description>
    </item>
    
    <item>
      <title>Python下使用Flask建立API</title>
      <link>https://codenow.me/articles/build_api_by_flask/</link>
      <pubDate>Wed, 10 Apr 2019 19:46:45 +0900</pubDate>
      
      <guid>https://codenow.me/articles/build_api_by_flask/</guid>
      <description> 前言 最近在学习微信小程序，前后端数据交互时，需要API提供数据操作。便学习通过python建立API。
示例 创建获取数据API @app.route(&amp;#39;/api/v1.0&amp;#39;, methods=[&amp;#39;GET&amp;#39;]) def get_data(): data = function # function为从数据库中获取内容的操作函数。 return jsonify({&amp;#39;data&amp;#39;:data}) # 返回json格式的数据。 操作结果 创建数据提交API @app.route(&amp;#39;/post/&amp;#39;, methods=[&amp;#39;POST&amp;#39;]) def post_data(): args = request.args.get(&amp;#39;arg_name&amp;#39;) # request.args.get提供了从url获取参数的功能，通过参数将数据传递后后端 status = post_function(args) # post数据的函数，成功返回200，失败返回错误信息。 return jsonify({&amp;#39;status&amp;#39;:status}) # 将信息返回给前端 上述情况中参数传递形式为：
http://127.0.0.1:5000/post/?name=小李&amp;amp;age=20 # name和age为参数名, 后面的值为具体参数值。  动态url规则下可以直接获取参数： app.route(&amp;#39;/post/&amp;lt;id&amp;gt;&amp;#39;, methods=[&amp;#39;POST&amp;#39;]) def post_data(id): # 直接将&amp;lt;id&amp;gt;的值作为函数参数 status = post_function(id) # psot id return jsonify({&amp;#39;status&amp;#39;:status}) 上述情况参数传递形式为：
http://127.0.0.1:5000/post/1 # 1为参数  </description>
    </item>
    
    <item>
      <title>Sentry Python Sdk</title>
      <link>https://codenow.me/articles/sentry-python-sdk/</link>
      <pubDate>Sun, 07 Apr 2019 23:58:18 +0800</pubDate>
      
      <guid>https://codenow.me/articles/sentry-python-sdk/</guid>
      <description>Sentry 是一个开源的实时错误报告工具，支持 web 前后端、移动应用以及游戏，支持 Python、OC、Java、Go、Node、Django、RoR 等主流编程语言和框架 ，还提供了 GitHub、Slack、Trello 等常见开发工具的集成。
 这周重新用 docker 部署了一下 Sentry server，比 python 部署确实方便多了，docker-compose 官方都给写好了，改改配置就可以直接上
server 端部署好之后，又看了一下 client 端是怎么做的。就感觉这个 SDK 做的真好，接入成本极低，以 Flask 为例，只要加上两行即可：
from raven.contrib.flask import Sentry sentry = Sentry(app, dsn=&#39;http://00d5b7d6d7f1498687430d160fd48ea8:ae6eaaf3c8d24d3f98537453da1f6a4f@localhost:9000/2&#39;)  于是仔细读了读 SDK 的实现，主要研究三个问题： 1. sentry 是怎么把 SDK 写得如此简洁的？ 2. sentry 是如何捕捉到要发送的错误信息的？ 3. sentry 是如何把错误信息发送到 server 端的？
注：以下使用的语言及 package 版本为： * python 3.6 * raven 6.10.0 * Flask 1.0.2
先看一下目录结构：
raven ├── conf # 配置相关 ├── contrib # 适配各框架的代码 ├── data # 证书等 ├── handlers	# 日志记录等 ├── scripts # 测试脚本 ├── transport # 实际发消息给服务端的东西 ├── utils # 一些内部工具 ├── __init__.</description>
    </item>
    
    <item>
      <title>工作中用到的python写log方式</title>
      <link>https://codenow.me/articles/python_usefull_log_method/</link>
      <pubDate>Sun, 07 Apr 2019 22:17:39 +0800</pubDate>
      
      <guid>https://codenow.me/articles/python_usefull_log_method/</guid>
      <description>1. 使用logger root@ubuntu:/home/hank# cat test_logger.py #! /usr/bin/python import logging import os class TestLogger: def __init__(self, log_name, log_dir=None, default_level=logging.DEBUG): self.logger = logging.getLogger(log_name) if not self.logger.handlers: log_dir = &amp;#34;/var/log/&amp;#34; if not log_dir else log_dir os.mkdir(log_dir) if not os.path.exists(log_dir) else None absolute_log = os.path.join(log_dir, log_name + &amp;#39;.log&amp;#39;) handler = logging.FileHandler(absolute_log) formatter = logging.Formatter(&amp;#39;%(asctime)-25s%(levelname)-8s%(message)s&amp;#39;) handler.setFormatter(formatter) self.logger.addHandler(handler) self.logger.setLevel(default_level) def debug(self, msg): self.logger.debug(msg) def info(self, msg): self.logger.info(msg) def error(self, msg): self.logger.error(msg) def critical(self, msg): self.logger.critical(msg) if __name__ == &amp;#39;__main__&amp;#39;: log_file, __ = os.</description>
    </item>
    
    <item>
      <title>Windows安装spark</title>
      <link>https://codenow.me/articles/spark_installation_onwindows/</link>
      <pubDate>Sun, 07 Apr 2019 20:48:40 +0800</pubDate>
      
      <guid>https://codenow.me/articles/spark_installation_onwindows/</guid>
      <description> 下载安装Java，安装版本为8 Java8下载地址 安装教程详见：菜鸟教程—Java安装
下载spark安装包 spark2.3.3下载地址
建议安装2.3.3版本，高版本的2.4.0在运行时会报错Py4j error。 下载后解压文件夹，并将路径配置到系统变量中。
系统环境变量中配置路径如下：
下载Hadoop支持包 百度网盘下载地址 提取码：ezs5
下载后解压，并添加系统变量：
下载并安装pycharm和anaconda 具体安装教程可自行百度。
安装后，将spark下的python中的pyspark拷贝到安装的python路径下的：Lib\site-packages 然后运行pip install py4j
配置pycharm运行spark环境 根据上图进行配置后即可运行spark程序。
配置日志显示级别 在spark\conf目录下创建log4j.properties配置文件，该目录下有template模板，可以直接复制。
然后将其中的：log4j.rootCategory=INFO, console 修改为 log4j.rootCategory=WARN, console
配置cmd下pyspark在jupyter下运行 编辑spark目录下：bin\pyspark2.cmd 修改其中对应部分为以下格式：
rem Figure out which Python to use. if &amp;quot;x%PYSPARK_DRIVER_PYTHON%&amp;quot;==&amp;quot;x&amp;quot; ( set PYSPARK_DRIVER_PYTHON=jupyter set PYSPARK_DRIVER_PYTHON_OPTS=notebook if not [%PYSPARK_PYTHON%] == [] set PYSPARK_DRIVER_PYTHON=%PYSPARK_PYTHON% )  </description>
    </item>
    
    <item>
      <title>Golang Linux Namespace Usage</title>
      <link>https://codenow.me/articles/golang-namespace/</link>
      <pubDate>Sun, 07 Apr 2019 20:22:21 +0800</pubDate>
      
      <guid>https://codenow.me/articles/golang-namespace/</guid>
      <description>总所周知 Docker 最早诞生于 Linux 平台，利用的是 Linux LXC 技术作为基础。Docker 作为一种 “轻量级虚拟机” 跑在通用操作系统中，那么势必就要对容器进行隔离，保证在宿主机内的独立性。
Namespace Overview 在 Linux Kernel 中有一组名为 Namespace 的系统调用 API。主要作用是封装了全局的系统资源的调用分配，在一个进程中隔离了其他进程的可见性，让自己 “拥有” 整个计算机的资源的能力。一个典型的用途就是容器的实现。
namespace 一种只有 4 个 API：
 clone：创建一个隔离的进程，可以通过参数控制所拥有的资源 setns：允许一个进程到现有的 namespace unshare：从现有 namespace 中移除一个进程 ioctl：用法发现 namespace 信息  接下来主要讨论如何创建一个具有隔离性的进程，也就是 clone 这个系统调用的用法。
clone 创建一个新的 namespace（进程），可以对其控制几个方面的资源（通过 CLONE_NEW* 这系列参数）。
 IPC：CLONE_NEWIPC，System V IPC 和 POSIX message queue Network：CLONE_NEWNET，网络设备等 Mount：CLONE_NEWNS，挂载点 PID：CLONE_NEWPID，进程的 ID User：CLONE_NEWUSER：用户或组的 ID UTS：CLONE_NEWUTS：Hostname 和 NIS domain  这里 CLONE_NEWNS 比较奇特，这是最早的一个参数，后面也想不到还有更多粒度的资源控制，所以这是一个历史遗留问题。
Namespace Usage 由于 Namespace 是 Linux 的系统调用，所以在其他操作系统是无法编译通过的。可以在 build 时候通过设置 GOOS = linux 解决，但是运行还是要放在 Linux 上运行。</description>
    </item>
    
    <item>
      <title>TiDB 源码学习：聚合查询</title>
      <link>https://codenow.me/articles/tidb-aggregation/</link>
      <pubDate>Sun, 07 Apr 2019 15:53:09 +0800</pubDate>
      
      <guid>https://codenow.me/articles/tidb-aggregation/</guid>
      <description>没了解过 Aggregation 的执行细节之前，感觉 Aggregation 比较神奇，它和普通的 SPJ 查询不太一样，Aggregation 会对数据分组并聚合计算，经过 Aggregation，整个数据的 schema 都会发生改变。
但其实，常见的 Aggregation 也并不复杂，从代码里看，和 Aggregation 相关的数据结构是这样的：
// LogicalAggregation represents an aggregate plan. type LogicalAggregation struct { logicalSchemaProducer AggFuncs []*aggregation.AggFuncDesc GroupByItems []expression.Expression // groupByCols stores the columns that are group-by items.  groupByCols []*expression.Column possibleProperties [][]*expression.Column inputCount float64 // inputCount is the input count of this plan. } type basePhysicalAgg struct { physicalSchemaProducer AggFuncs []*aggregation.AggFuncDesc GroupByItems []expression.Expression } // PhysicalHashAgg is hash operator of aggregate.</description>
    </item>
    
    <item>
      <title>互联网之子 Aaron Swarts 想要看到的世界</title>
      <link>https://codenow.me/articles/aaron_huoju/</link>
      <pubDate>Sun, 07 Apr 2019 14:19:45 +0900</pubDate>
      
      <guid>https://codenow.me/articles/aaron_huoju/</guid>
      <description>作者: Jade &amp;amp; 霍炬  链接：互联网之子 Aaron Swarts 想要看到的世界 
 Jade 和我偶尔会聊起一些宏大的话题，最近聊到了 Aaron 和互联网创建者们的一些历史。她觉得应该正经的来一次对话，记录下来分享给其他人。我们约了个时间，原计划聊 2 个小时，实际上聊了 5 个小时。最后形成了一篇交谈形式的文字，她称之为文字版的 Podcast。我很喜欢这种形式，我也更认同文字的价值，更好分享，更好检索，也更好修改或者摘录使用。以后我们应该还会继续这样的对话，这次聊天里面很多东西都可以继续讲下去。希望你也喜欢这个形式。
网络和 BBS 在我们现在知道的互联网诞生之前就存在了，普通人有机会接触网络的历史，至今也有 30 多年了。虚拟世界的时间进度远远比现实世界快，在中国，也有“互联网是属狗的，一年当作七年用这个说法”。按照这个比例推测，换算到现实世界，互联网实际上走过了相当于 200 年左右的历史了。对它的研究已经可以产生一个“互联网考古学”之类的新学科了，然而没有多少人意识到这件事，也没多少人对这些历史和人物有兴趣。尽管我认为这些非常重要，其中有太多的教训和经验今天仍然可以学习。而且，这些历史也不应该被忘掉。
Usenet 今天已经变成了下载者的乐园，但是它的废墟里埋葬了太多的历史和欢笑血泪。一些人已经消失，一些人还在积极工作，一些人已经走上了另外一条道路，还有一些人已经离开了我们。如果你从 80 年代就对整个网络世界有所了解，你会发现到今天一切都是相连的，从拨号 BBS 到区块链，有一条暗线始终存在。差不多也到了挖掘这些故事的时候了。
01 自由的代价 Jade：首先问个题外话，你为什么会选择在寒冷的加拿大生活和开发产品？
霍炬：几年前我觉得世界似乎变得越来越混乱，我和太太就想找一个“安全的地方”躲起来。于是我去读了所有可能去的国家的历史和政治制度，最后认为最安全的两个地方是新西兰和加拿大。但新西兰太偏远，科技和互联网不够发达，加拿大科技水平很高，创新能力也好，于是，就加拿大了。
Jade：没想到一个八卦问题引发了如此深刻的答案，吓了我一跳。之所以咱们决定有这次对谈，我记得是有一次我们聊起了 Aaron Swarts，你给我推荐了关于他的纪录片（互联网之子 The Internet&amp;rsquo;s Own Boy: The Story of Aaron Swartz (2014)），然后就一发不可收拾地聊起了一大堆宏大的主题。能不能从你的角度再介绍一下 Aaron 这个人，我们都知道他是一个互联网天才，14 岁参与制订 RSS 标准，26 岁在 MIT 事件的压力下自杀。为什么你觉得这个人很重要？他带来了什么？
霍炬：Aaron 最常见的介绍是“reddit 联合创始人，RSS 参与者，Markdown 标准参与者”。但是这些不是我想说的重点，重点是他是一个承接上一代和下一代的人物。应该是承接互联网创建者们的理念，并且用来改造世界的人。
Aaron 深受 John Perry Barlow（电子前线基金会 EFF 的创始人）的影响。在 Aaron 中学时代，John 到他们学校演讲，Aaron 听了这个演讲之后，深受影响。后来 Aaron 的爸爸说那天他回家就像变了一个人一样。以及后来 Aaron 和 Tim Berners-Lee 在一起工作，等等。按照他的年龄，很难想象和这些互联网的创建者们一起工作和活动。但是他和他们相处很好，这些人也都喜欢他。</description>
    </item>
    
    <item>
      <title>两阶段提交协议</title>
      <link>https://codenow.me/articles/2pc/</link>
      <pubDate>Sun, 31 Mar 2019 22:12:05 +0800</pubDate>
      
      <guid>https://codenow.me/articles/2pc/</guid>
      <description>两阶段提交协议
在分布式系统中每个节点都可以知道自己的操作是成功还是失败，但是无法知道其他节点的状态。为了保证一个事务的 ACID 特性，一个节点发生失败就要在所有节点上执行 rollback 操作。需要引入一个 协调者 来维护各个 参与者 的状态，以保证最终一致。
2pc 并不是万能的，需要满足一定的条件才可以使用：
 一个节点是协调者，其他节点作为参与者，相互之前可以通信 每个节点要有 redo log 机制，而且存在持久化存储中 节点不会永久损坏，一定时间会重启恢复  Tow-phase Commit Protocol 首先引入几个概念：
 协调者：维护所有节点 参与者：执行具体操作的节点 prepare phase：准备阶段，写入日志，资源加锁 commit phase：执行阶段，根据协调者指令执行，资源解锁  上图中 ① 和 ② 表示 prepare phase，③ 和 ④ 表示 commit phase。
在 prepare phase 阶段，协调者发出信息让参与者准备。参与者接受到信息以后一般会做两件事情：
 根据需要执行的操作生成 redo 日志，用于后续 commit 或者 rollback 给所需的资源上锁，防止其他程序获取  参与者完成这两个操作会把结果通知协调者。
当协调者接受到参与者在 prepare phase 阶段的响应（无论 Yes 还是 No），就会进入 commit phase 阶段。在该阶段，如果接受到 prepare phase 的响应所有都是 Yes 时候，会发出 Commit 指令；只要收到一个 No，发出的就是 Rollback 指令。</description>
    </item>
    
    <item>
      <title>Python3 Crontab</title>
      <link>https://codenow.me/articles/python3-crontab/</link>
      <pubDate>Sun, 31 Mar 2019 21:43:04 +0800</pubDate>
      
      <guid>https://codenow.me/articles/python3-crontab/</guid>
      <description>这周需要在容器中跑一个定时脚本
现成的方式有很多： 1. 直接使用 ubuntu:14.04 的镜像，内置 crontab 和 python3.4 2. 想用 python3.6 的话，可以用 python:3.6 的镜像装一个 crontab 也成 3. dockerhub 上别人应该也有这种需求，捞一个就成
不过我还是想自己拼一个，要求： 1. 需要包含 crontab 和 python3.6 2. 需要能支持使用 pip 安装其他扩展包 3. 镜像要尽量小
思路以及需要注意的地方大概是： 1. 装上各种必要的东西 2. 设置时区 3. 配置好 crontabfile 4. 运行时启动 crond，并用 tail -f 来保证容器不退出
目前只是做了个能用的，用 python3.6-alpine 做源，往上怼了点够自己使用的东西，先实现了需求
下一步是直接用 alpine 或者 buildpack-deps 来构建镜像，以此精简，留着 TODO 吧
我写了个 demo 放到了 github 上: https://github.com/WokoLiu/python3-cron ，也同步到了 dockerhub 上 docker pull woko/python3-cron
文件结构是这样的：
. ├── Dockerfile ├── crontabfile ├── scripts.</description>
    </item>
    
    <item>
      <title>TiDB 源码学习：常见子查询优化</title>
      <link>https://codenow.me/articles/tidb-subquery-optimization/</link>
      <pubDate>Sun, 31 Mar 2019 13:19:47 +0800</pubDate>
      
      <guid>https://codenow.me/articles/tidb-subquery-optimization/</guid>
      <description>根据 TiDB 中的子查询优化技术 这篇文章的介绍，TiDB 在处理关联子查询时引入了 Apply 算子。然后使用关系代数将 Apply 算子等价转换成其他算子，从而达到去关联化的目的。理论上，所有的关联子查询都可以去关联化，具体的理论知识可以看这篇博客：SQL 子查询的优化。
本文从代码角度，梳理一下常见关联子查询的优化。处理过程主要有两个阶段：
 重写阶段：在将语法树转换成逻辑查询计划时，将子查询重写成带有 Apply 算子的查询计划，这部分主要是由 expressionRewriter 负责 去关联化：在优化逻辑查询计划时，尝试将 Apply 算子替换成其他算子，从而去关联化，这部分主要有 decorrelateSolver 负责  expressionRewriter 简介 expressionRewriter 负责将子查询重语法树写成带有 Apply 算子的查询计划。为了实现这一功能，需要能够遍历语法树，expressionRewriter 实现了 Visitor 接口，能够遍历语法树中的各个节点，在遍历过程当中完成重写工作，它的核心的方法主要是 Enter 和 Leave。
Visitor 接口一般会被这样使用：
func (n *CompareSubqueryExpr) Accept(v Visitor) (Node, bool) { newNode, skipChildren := v.Enter(n) if skipChildren { return v.Leave(newNode) } n = newNode.(*CompareSubqueryExpr) node, ok := n.L.Accept(v) //...  n.L = node.(ExprNode) node, ok = n.</description>
    </item>
    
    <item>
      <title>Spark累加器和广播变量</title>
      <link>https://codenow.me/articles/spark-broadcast_accumulator/</link>
      <pubDate>Sat, 30 Mar 2019 11:21:36 +0800</pubDate>
      
      <guid>https://codenow.me/articles/spark-broadcast_accumulator/</guid>
      <description>累加器 累加器提供将工作节点的值聚合到驱动器程序中的功能，且实现语法简单。
示例图：
#python中累加空行 file = sc.textFile(inputfile) blankLines = sc.accumulator(0) # 创建Accumulator(Int) def extractCallSigns(line): global blankLines if line == &amp;#34;&amp;#34;: blankLines += 1 return line.split(&amp;#39; &amp;#39;) callSigns = file.flatMap(extractCallSigns) callSigns.saveAsTextFile(outputPath) print(&amp;#39;blank Lines : %d&amp;#39; %blankLines.value) 实际使用中可以创建多个累加器进行计数
validSignCount = sc.Accumulator(0) invalidSignCount = sc.Accumulator(0) 广播变量 简介 正常情况中，spark的task会在执行任务时，将变量进行拷贝。当每个task都从主节点拷贝时，程序的通信和内存负担很重。 使用广播变量后，主节点会将变量拷贝至工作节点，任务从工作节点获得变量，而不用再次拷贝，此时变量被拷贝的次数取决于工作节点的个数。
#在Python中使用广播变量 signPrefixes = sc.broadcast(loadCallSignTable()) def processSignCount(sign_count, signPrefixes): country = lookupCountry(sign_count[0], signPrefixes.value) count = sign_count[1] return (country, count) countryContactCounts = (contactCounts.map(processSignCount).reduceByKey((lambda x, y:x+y))) countryContactCounts.saveAsTextFile(ooutputPath) 基于分区进行操作 基于分区对数据进行操作可以让我们避免为每个数据元素进行重复的配置工作。 Spark提供基于分区的map和foreach。</description>
    </item>
    
    <item>
      <title>How to Use Hugo</title>
      <link>https://codenow.me/articles/how-to-use-hugo/</link>
      <pubDate>Thu, 28 Mar 2019 23:51:40 +0800</pubDate>
      
      <guid>https://codenow.me/articles/how-to-use-hugo/</guid>
      <description>一、介绍 1. 优点   Hugo是一个用Go语言编写的静态网站生成器，它使用起来非常简单，相对于Jekyll复杂的安装设置来说，Hugo仅需要一个二进制文件hugo(hugo.exe)即可轻松用于本地调试和生成静态页面。 Hugo生成静态页面的效率很高，几乎是瞬间完成的，而之前用Jekyll需要等待。 Hugo自带watch的调试模式，可以在我修改MarkDown文章之后切换到浏览器，页面会检测到更新并且自动刷新，呈现出最终效果，能极大的提高博客书写效率。 再加上Hugo是使用Go语言编写，已经没有任何理由不使用Hugo来代替Jekyll作为我的个人博客站点生成器了。   2. 静态网站文件的两种方式：   放到自己的服务器上提供服务：需要自己购买服务器 把网站托管到 GitHub Pages：需要将静态页面文件 push 到 GitHub 的博客项目的 gh-pages 分支并确保根目录下有 index.html 文件。   3. 官网   Hugo语言官方中文文档地址：http://www.gohugo.org/ Hugo官方主页：https://gohugo.io/   二、安装Hugo 1. 二进制安装（推荐：简单、快速） 到 Hugo Releases (https://github.com/gohugoio/hugo/releases)下载对应的操作系统版本的Hugo二进制文件（hugo或者hugo.exe）
 下载解压后添加到 Windows 的系统环境变量的 PATH 中即可，不需安装。 可以直接放在C:\Users\chunt\go\bin下，这样就不需要添加系统环境变量  Mac下直接使用 Homebrew 安装：
 brew install hugo 二进制在 $GOPATH/bin/, 即C:\Users\chunt\go\bin  2. 源码安装(不好用，go get有些下载不下来) 源码编译安装，首先安装好依赖的工具：
 Git Go 1.</description>
    </item>
    
    <item>
      <title>使用 RMDBS 存在树结构数据</title>
      <link>https://codenow.me/articles/rmdbs-tree-datastruct/</link>
      <pubDate>Sun, 24 Mar 2019 23:41:36 +0800</pubDate>
      
      <guid>https://codenow.me/articles/rmdbs-tree-datastruct/</guid>
      <description>在关系型数据库中存储树形结构是比较麻烦的事情，因为数据库都是基于行存储的结构，要满足树形数据结构的添加、删除、查询、修改是一件比较棘手的事情。
已经有一些解决方案可以解决：
这篇文章介绍一下，使用「闭包表」来处理树形结构存储。
选择「闭包表」主要是基于查询、插入、删除、移动都比较简单，更要的是都可以使用一条 SQL 就能处理完成。
CREATE TABLE Comments ( comment_id SERIAL PRIMARY KEY, comment TEXT NOT NULL ); 树形结构典型就是评论和部门成员关系，以评论为例，我们同时又要支持完整增删改查的功能，大致结构如下： 为了满足这种复杂的关系，需要有另外一个表来存储这种结构。
CREATE TABLE TreePaths ( ancestor BIGINT NOT NULL, descendant BIGINT NOT NULL, PRIMARY KEY(ancestor, descendant), FOREIGN KEY (ancestor) REFERENCES Comments(comment_id), FOREIGN KEY (descendant) REFERENCES Comments(comment_id) ); ancestor 作为每个评论节点的祖先，descendant 作为每个评论节点的后代。
 这里的祖先和后代都是泛指所有祖先和后代，而不是特指直接的祖先和后代
 接着构造一批数据插入 Comments 和 Tree Paths 中
insert into comments(comment_id, comment) values (1, &amp;#39;这个 Bug 的成因 是什么&amp;#39;); insert into comments(comment_id, comment) values (2, &amp;#39;我觉得是一个空指针&amp;#39;); insert into comments(comment_id, comment) values (3, &amp;#39;不，我查过了&amp;#39;); insert into comments(comment_id, comment) values (4, &amp;#39;我们需要查无效输入&amp;#39;); insert into comments(comment_id, comment) values (5, &amp;#39;是的，那是个问题&amp;#39;); insert into comments(comment_id, comment) values (6, &amp;#39;好，查一下吧&amp;#39;); insert into comments(comment_id, comment) values (7, &amp;#39;解决了&amp;#39;); insert into treepaths(ancestor, descendant) values (1, 1); insert into treepaths(ancestor, descendant) values (1, 2); insert into treepaths(ancestor, descendant) values (1, 3); insert into treepaths(ancestor, descendant) values (1, 4); insert into treepaths(ancestor, descendant) values (1, 5); insert into treepaths(ancestor, descendant) values (1, 6); insert into treepaths(ancestor, descendant) values (1, 7); insert into treepaths(ancestor, descendant) values (2, 2); insert into treepaths(ancestor, descendant) values (2, 3); insert into treepaths(ancestor, descendant) values (3, 3); insert into treepaths(ancestor, descendant) values (4, 4); insert into treepaths(ancestor, descendant) values (4, 5); insert into treepaths(ancestor, descendant) values (4, 6); insert into treepaths(ancestor, descendant) values (4, 7); insert into treepaths(ancestor, descendant) values (5, 5); insert into treepaths(ancestor, descendant) values (6, 6); insert into treepaths(ancestor, descendant) values (6, 7); insert into treepaths(ancestor, descendant) values (7, 7); 这里需要解释一下 treepaths 存储关系的逻辑：</description>
    </item>
    
    <item>
      <title>[Go]Exercise of a Tour of Go</title>
      <link>https://codenow.me/articles/exercise_of_a_tour_of_go/</link>
      <pubDate>Sun, 24 Mar 2019 22:58:30 +0800</pubDate>
      
      <guid>https://codenow.me/articles/exercise_of_a_tour_of_go/</guid>
      <description>这周学了学 golang，做个记录
学习网站：https://tour.golang.org
对应的中文版：https://tour.go-zh.org
这周主要学习内容是刷了一遍上面这个教程，虽然够官方，但讲解并不细致，很多需要自行 google
顺便，第一次打开教程和在线运行代码都需要科学上网，但打开一次后所有内容就都被缓存下来了，火车上都可以翻页学习。也不方便的话可以用中文版，或者本地安装，教程上也都有说。
知识点记录 go 项目结构  必须要有 package import 用的是字符串 首字母大写的是导出名(exported name)，可以被别的包使用，有点类似于 python 的 all 只有 package main 可以被直接运行 运行入口 func main() {}  基础部件  函数以 func 定义，每个参数后必须带类型，必须规定返回值类型，可返回多个值，返回值可预先命名，函数是第一类对象(first class object) 变量以 var 定义，定义时必须规定类型，可在定义时赋值，函数内的变量可以不用 var 而用 := 来定义+赋值 常量以 const 定义，不能使用 := 语法，仅支持基础类型 基础类型是 bool, string 和各种数字，byte = uint8, tune = int32 类似于 null, None 的，是 nil  语法  if 不需要小括号，但必须有大括号；if 中可以有一条定义变量的语句，此变量仅在 if 和 else 中可用 for 是唯一的循环结构，用法基本等同于 Java 里的 for + while，同样没有小括号，但有大括号，for {} 是无限循环 switch 的每个 case 后等同于自带 break，但可以用 fallthrough 直接跳过判断而执行下一条 case 内的语句；没有匹配到任何一个 case 时会运行 default 里的内容；没有条件的 switch 可以便于改写 if-elseif-else defer 可将其后的函数推迟到外层函数返回之后再执行，多个 defer 会被压入栈中，后进先出执行 select-case 语句可同时等待多个 chan，并在所有准备好的 case 中随机选一个执行 for-range 可以对 array, map, slice, string, chan 进行遍历 make 可用来为 slice, map, chan 类型分配内存及初始化对象，返回一个引用，对这三种类型使用make时，后续参数含义均不同  其他数据类型  pointer 类似 C，没有指针运算 struct 内的字段使用 .</description>
    </item>
    
    <item>
      <title>代码「阅读」覆盖率</title>
      <link>https://codenow.me/articles/code-reading-coverage/</link>
      <pubDate>Fri, 22 Mar 2019 10:42:05 +0800</pubDate>
      
      <guid>https://codenow.me/articles/code-reading-coverage/</guid>
      <description>最近本人在阅读一些开源项目的代码，说到如何阅读开源代码，特别是超出自己能力范围的开源项目，可以说的内容还是挺多的。今天分享一个比较「偏」的：代码「阅读」覆盖率。
看一个代码库，刚开始可能是一头雾水，再咬咬牙坚持一下，一般能梳理出大致的脉络，比如服务的启动流程是怎样的，服务主要由那几个组件构成，它们之间是如何通信协作的。再往后则是一点一点了解代码是如何支持各种不同场景的，加深对代码的理解。代码「阅读」覆盖率在第三个阶段会有一定的帮助。
所谓的代码「阅读」覆盖率，和代码测试覆盖率概念类似，后者统计的是运行测试时哪些代码被运行过，所占比例是多少，前者统计的则是哪些行代码已经理解了，哪些还不理解。通过阅读覆盖率的统计，我们能更好衡量对代码库的了解程度，增加我们深入阅读代码的乐趣。
为了实现阅读覆盖率的统计，我开发了一个简陋的浏览器插件，主要有以下功能：
功能一：基于 github，支持在 github 代码页面中标记哪些代码已经理解，效果如下图所示：
直接借助 github 代码页面来显示代码理解情况，直接扩展 github 自带的菜单，增加标记功能 （图中的 mark as read 和 mark as unread 菜单项），这样能够减少一些工作量。
功能二：统计代码阅读覆盖率
效果如下所示：
在文件列表和代码界面显示百分比。
目前插件还很简陋，不过实现方式很简单，就不分享代码了，感兴趣的同学可以自己试着开发一个。
小结，阅读学习开源代码是一种比较硬核的游戏，增加阅读覆盖率的统计，是为了给这个硬核游戏添加一些可视化元素，就像塞尔达荒野之息里的地图，你能通过它看到自己探索了哪些神庙。这类手段可以延长游戏成就带来的快感，每次当我理解了一些代码后去把它们标记出来，还是很开心的，每次对代码渐渐失去兴趣时，看到统计的百分比还比较低，就又有了研究的动力。</description>
    </item>
    
  </channel>
</rss>
<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>翻译 on ATTS</title>
    <link>https://codenow.me/translation/</link>
    <description>Recent content in 翻译 on ATTS</description>
    <generator>Hugo -- gohugo.io</generator>
    <lastBuildDate>Fri, 15 Mar 2019 07:28:29 +0000</lastBuildDate>
    
	<atom:link href="https://codenow.me/translation/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>如何帮助人们从pip迁移到conda?</title>
      <link>https://codenow.me/translation/how_to_help_people_migrating_from_pip_to_conda/</link>
      <pubDate>Sun, 21 Apr 2019 21:48:51 +0800</pubDate>
      
      <guid>https://codenow.me/translation/how_to_help_people_migrating_from_pip_to_conda/</guid>
      <description>原文地址： https://discuss.python.org/t/how-to-help-people-migrating-from-pip-to-conda/1474
有两种方法可以解决这样的迁移问题：减少摩擦，或者提供胡萝卜（有意义的好处）。
Conda已经提供了胡萝卜，它起作用了。一般来说，这足以克服摩擦（尽管并不总是——见我上面的引言）。
实际上，我们看到的是非Conda用户的挫折感，他们没有胡萝卜，但还不足以克服摩擦。人们越接近孤立的工作包安装而不需要Conda，就会产生更多的虚构。
简言之，基于venv的工具的“成长故事”很弱，因为如果不重新启动，您将无处可逃。解决这个问题不需要任何其他的软件包管理器——他们完全可以自由地说：“是的，我们告诉过你，当你依赖于系统安装时，错误是正确的，但是我们很高兴你现在在这里，让我们开始工作。”如果他们的论点是，基于venv的工具是最初的问题，那么他们不必从中找到放弃的地方，从中走出来。
（Conda和其他系统包管理器在这里都是可互换的。没有人希望apt/yum安装的软件包只适用于高度定制的venv，对吗？）</description>
    </item>
    
    <item>
      <title>Sharingpwswithgopass</title>
      <link>https://codenow.me/translation/sharingpwswithgopass/</link>
      <pubDate>Sun, 21 Apr 2019 16:20:07 +0900</pubDate>
      
      <guid>https://codenow.me/translation/sharingpwswithgopass/</guid>
      <description>作者： Woile 原链接： Sharing passwords using gopass, git and gpg  （删减版）
不想再把你的密码放在不可靠却方便的地方？ 不想再在 slack，notes 这些不可信赖的平台上分享密码？ 不想再在不同的地方放你的团队密码？ 如果对于上面的问题你的回答如果是 yes，那你应该会觉得这篇文章有用。
背景 我为了寻找一个安全的方式去储存我的密码花了不少时间。当然，除了安全，我还希望有以下性能： - 密码存在云里 - 设备之间可以简单同步 - 可以很方便地与人共享 我找到的解决方案是 gopass
gopass 是怎么工作的 gopass 就像是有多一份电池的 pass（unix 密码管理器） 在这里面，它拥有的且和我相关的性能有 1. 用 gpg 进行加密； 2. 用 git 进行密码同步； 3. 不同属性的密码可以放在不同的储存地方（个人、公司等）； 4. 每个存储地方指向不同的仓库； 5. 一个存储地址支持多个人运用。接下来我们称他们为收信人
虽然它还缺乏一些文档和命令，但是我们不必害怕去尝试它。 我很高兴 gopass 使用了 gpg。 它唯一的缺点，我想是它正式的 windows 版本还没发布。
安装 你可以看看这个网站里介绍的安装或者可以在 gopass repo 里得到更多的信息。
使用 首先，我们需要一个 gpg 密钥。我们需要 gpg cli 去创建一个，如果你安装了 gopass，那你的系统里应该就有了。</description>
    </item>
    
    <item>
      <title>Why Django Is The Popular Python Framework aMONG wEB dEVELOPERS?</title>
      <link>https://codenow.me/translation/why_django/</link>
      <pubDate>Sun, 21 Apr 2019 14:59:56 +0800</pubDate>
      
      <guid>https://codenow.me/translation/why_django/</guid>
      <description>原文地址
如今，许多的后端开发人员选择使用Python。Python已经称为最受欢迎的Web开发语言之一，它的灵活性和多功能行是它能够取得如此成功的重要原因之一。从开发简单代码到数据分析和机器学习，Python已成为许多开发人员的首选语言。
有许多框架是可以和Python一起使用的，这些框架基本上允许开发人员选择一个平台，他们可以根据自己的喜好自定义并自由测试。在Python的所有框架中，Django似乎是最受欢迎的选择。实际上，在2018年的Stock Overflow Survey中，Django被列为最受欢迎的框架之一，58%的开发者投票支持。
很明显，许多开发人员更喜欢使用Django进行Web项目开发，如果您尚未使用Django并且想知道热点是关于什么，这里有一些原因可以解释为什么Django在Web开发人员中很受欢迎。
Django的流行 Python是最简单的编码语言之一，Django是一个基于Python的Web开发框架，具有Python的所有最佳功能 - 易于维护，编码简单，干净，调试速度更快。 Django保留了Python的真正本质。 它消除了编码的复杂性，并且不希望编码中有太多冗余，从而更容易将开发成本降至最低，并为简化调试铺平了道路。
Django如此受欢迎，以至于世界上一些顶级应用程序都是用它开发的。 世界上一些顶级内容驱动的网站，如华盛顿邮报，纽约时报，卫报和许多其他网站使用Django来处理来自其网站的巨大流量并保持其高水平的性能。 Dropbox是世界顶级云存储平台之一，也主要与Django一起运行，用于存储，同步和共享选项。 Django框架也用于Instagram，Spotify，Disqus，YouTube，Mozilla等，帮助开发人员保持更新的新功能和新的更新，使他们能够快速工作。 其中一些应用程序使用Django作为主要平台运行，而其他一些应用程序部分使用它。 尽管如此，Django已成为目前许多成功网站运营的一部分，难怪它正在快速攀升人气图！
易于扩展和扩展 Django的组件可以被删除，添加或修改，使得使用冗余代码变得简单易行。 此外，它可以完全自由地向应用程序添加第三方软件包，从而减少了开发人员的大量工作。 除此之外，如果代码运行冗长，可以不必担心找到另一个平台，因为Django可以被缩放以容易地包含任何长度的代码。
互动而有益的社区 Django是一个免费的开源框架，意味着框架将始终更新为最佳版本。 Django有大量文档证明您拥有使用它所需的所有信息和资源。 当您想讨论使用Python Django开发的新可能性或需要一些特定部分的帮助时，Django社区非常庞大且具有交互性，您可以快速获得答案。 解决您对Django的疑虑或问题很简单 - 只需Google搜索您的问题，您就可以立即获得解决方案！
有时，当一个新的开发人员加入项目的中间时，感觉很难赶上当前的开发阶段，并在编码阶段快速进入正轨。 但是，随着Django基于MTV架构 - 模型 - 模板 - 视图架构 - 工程中不同任务的代码保持分离。 这使得加入团队的新开发人员更容易达到速度并从第一天开始轻松地开始工作。 自动安全
Django为其构建的应用程序提供安全保护。 它在您启动开发产品之前使用自动检查来查找任何错过的安全漏洞。 它还有助于识别和减少Python中编码带来的一些最常见的安全错误，并保护应用程序免受错误。
Python与Django框架相结合，为创建一个可靠且高度安全的平台来开发Web开发项目奠定了基础。 随着新功能和功能的引入，开发人员使用Django并尽快启动他们的项目变得越来越简单。</description>
    </item>
    
    <item>
      <title>Example of Equi Depth Histograms in Databases</title>
      <link>https://codenow.me/translation/example-of-equi-depth-histograms-in-databases/</link>
      <pubDate>Sun, 14 Apr 2019 23:05:56 +0800</pubDate>
      
      <guid>https://codenow.me/translation/example-of-equi-depth-histograms-in-databases/</guid>
      <description>原文链接：https://stackoverflow.com/a/14284218
警告：我不是一个数据库底层的专家，所以这只是一个简单泛泛的回答。
查询编译器会将查询（一般以 sql 的形式）转换成一个查询计划并得到查询结果。查询计划里面包含数据库引擎的低层次指令，比如扫描表 T 在 C 列查询 V 值；在 T 表使用索引 X 来定位 V 等等。
查询优化是指编译器要在一些列查询计划中判断出哪个代价最小。代价包括始终时间，IO 单宽，存储空间，cpu 等等。从概念上讲，查询编译器是从一组计划空间中衡量每一种计划的代价，选择它能找到的最小代价的。
上面提到的这些取决于读写的数据条数，数据是否能够被索引定位到，哪些列会被被使用，数据尺寸，以及多少磁盘空间会被占用。
这些数据很多时候取决于表中到底存了多少数据。比如这样一个查询：select * from data where pay &amp;gt; 100 ，其中 pay 被索引。如果 pay 列没有大于 100 的值，那么这个查询代价会很小。使用索引扫描就行了。相反的，结果可能包含了整张表。
这块儿，直方图会起作用（等高直方图只是直方图的其中一种）。在前面的查询中，直方图可以在 O(1) 时间复杂度里对查询匹配的数据行数进行一个评估，在不需要了解数据库里到底有哪些数据的情况下。
实际上，编译器是在数据的摘要之上&amp;rdquo;执行&amp;rdquo;了查询。直方图就是这个摘要。直方图在评估代价和查询算子的结果大小上很有用，比如：表连接结果大小，插入和删除时被影响到的页数等。
以一个简单的内连接为例，假如我们知道用来连接两张表的列的数据分布：
Bins (25% each) Table A Table B 0-100 151-300 101-150 301-500 151-175 601-700 176-300 1001-1100  可以很容易看到 A 表中 50% 的数据和 B 表中 25% 的数据会参与到查询当中。如果有唯一列的话，我们可以评估连接的结果大小应该是 max(.5 * |A|, .25 * |B|)。这是很简单的一个列子。在很多的场景中，统计分析需要更复杂一些的数学知识。对于连接来说，经常通过算子的直方图技术连接的评估直方图。</description>
    </item>
    
    <item>
      <title>「译」Python 项目应该都有什么？</title>
      <link>https://codenow.me/translation/what-every-python-project-should-have/</link>
      <pubDate>Sun, 14 Apr 2019 21:59:43 +0800</pubDate>
      
      <guid>https://codenow.me/translation/what-every-python-project-should-have/</guid>
      <description>原文地址
 Python 语言在过去的几年有着突飞猛进的发展，社区也在快速发展。在发展过程中，社区中出现了许多工具保持着资源的结构性和可获取性。在这篇文章中，我将提供一个简短列表，让每个 Python 项目中都具有可访问性和可维护性。
requirements.txt 首先， requirements.txt 在安装项目时候是十分重要的，通常是一个纯文本文件，通过 pip 安装，每行一个项目的依赖。
真是简单又实用。
你也可以有多个用于不同目的 requirements.txt。例如，requirements.txt 是让项目正常启动的依赖，requirements_dev.txt 是用于开发模式的依赖，requirements_docs.txt 是生成文档的依赖（像 Sphinx 需要的主题）
setup.py setup.py 文件在通过 pip 安装时候时候是十分重要的。编写容易，很好的可配置性并且可以处理很多事情，例如导入，项目元数据，更新源，安装依赖项等等。
可以查看 setuptools 文档获取更多的信息。
正确的项目结构 项目结构至关重要。有了一个组织良好的结构，它会更容易组织的东西，找到某些源文件，并鼓励其他人贡献。
一个项目目录应具有类似的结构
root/ docs/ tests/ mymodule/ scripts/ requirements.txt setup.py README LICENSE  当然，这不是组织项目的唯一方法，但这肯定是最常用的模板。
测试 单元测试对项目十分重要，可以保证代码的稳定性。我推荐 unittest 模块，因为它是内置的，并且足够灵活，完成正确工作。
还有其他可用于测试项目的库，例如 test.py 或 nose。
文档 如果你开发一个项目，我确信你不只是为你自己写。其他人也要必须知道如何使用你的项目。即使你只是为自己编写的项目（虽然是开源的目的），但是一段时间后不开发后，你一定不会记得你的代码中发生的任何事情（或API）。
因此，为了实现可重用的代码，你应该：
 设计一个简单的API，易于使用和记忆 API应该足够灵活，容易配置 记录相关使用例子 例子不要追求 100% ，最合适的是覆盖 80％ 。  为了充分的记录你的代码，你应该使用特殊的工具开完成文档工作，例如 Sphinx 或者 mkdocs ，所以你可以使用一个流行的标记语言（rst或markdown）来生成具有适当引用链接的漂亮的文档。</description>
    </item>
    
    <item>
      <title>Did_you_know_you_can_easily_extend_and_expand_your_datacenter_footprint</title>
      <link>https://codenow.me/translation/did_you_know_you_can_easily_extend_and_expand_your_datacenter_footprint/</link>
      <pubDate>Sun, 14 Apr 2019 18:16:56 +0800</pubDate>
      
      <guid>https://codenow.me/translation/did_you_know_you_can_easily_extend_and_expand_your_datacenter_footprint/</guid>
      <description>您是否知道可以轻松地延伸和扩展您的数据中心占用空间? 原文链接：http://app.learn.vmware.com/e/es?s=279193683&amp;amp;e=2902981&amp;amp;elqTrackId=80b432a7915c49a0a70c7d2846b7ff14&amp;amp;elq=52464596ac594d2d93bd227a6575bdc5&amp;amp;elqaid=25584&amp;amp;elqat=1
翻译如下：
现代IT团队承受着难以置信的压力，要以越来越快的速度创新和推出产品和服务，但在快速扩展产品方面存在许多障碍。其中最主要的挑战是如何快速轻松地利用公共云提供的无限可伸缩性、随需应变能力和灵活的消费。
AWS上的VMware Cloud是一种随需应变服务，它允许您跨基于websphere的云环境运行应用程序，并访问广泛的本机AWS服务。
该服务由VMware Cloud Foundation™提供支持，集成了VMware的旗舰计算、存储和网络虚拟化产品(VMware vSphere、VMware vSAN和VMware NSX)以及VMware vCenter management，并优化为在弹性的、裸机AWS基础设施上运行。
有了这项服务，客户可以使用熟悉的VMware工具管理基于云的资源。</description>
    </item>
    
    <item>
      <title>只需 4 步，改善你的编程工具</title>
      <link>https://codenow.me/translation/4waysdeveloperimprovetools/</link>
      <pubDate>Sun, 14 Apr 2019 13:43:03 +0900</pubDate>
      
      <guid>https://codenow.me/translation/4waysdeveloperimprovetools/</guid>
      <description>作者： bmusings 原链接： 4 Ways Every Software Developer Should Improve Their Tools
工具可以让开发人员的想法转换成为计算机能够理解的确切指令。 从文本编辑器到源代码控制，为了技术和效率，它们是我们每天使用上百次的伙伴。和木匠不同，当我们想要更好的工具时，不能直接去商店里买一把更好的锤子。 这引发了一个问题： 我们如何去改善我们的日常工具。 下面我介绍 4 个能够升级工具的方法。
学习快捷键 设置快捷键和别名是我们使用现有工具最方便最有效的方法。 它通过使用键盘输入代替鼠标点击操作，从而节省时间。 一个人机交互领域出名的法则 Fitt&amp;rsquo;s Law 指出，点击目标所需的时间和指针的距离成正相关，和目标的大小成反比。也就是说，更小更远的目标比更大更近的目标需要花更多的时间。我见过很多次有些专业的软件工程师使用键盘在三个越来越小的目录花费了很多时间只为了操作一个指令，这真是荒谬。学习快捷键进行指令操控会让你把时间控制到常量级别（0.1 - 0.4 秒之间）
大多数文字编辑器、浏览器还有其它界面工具都有一套可以让你马上使用的快捷键，不要想着一下子就把它们都学会。从一两个开始，把它们拿下，然后再用多几个再熟练，重复这个过程即可。
有时候你需要使用一系列键盘操作才能完成一个指令，这时候别名和宏就派上用场了。你只需要把你常用的一系列操作用一个简单明了的命令代替就可以了。做好得了的话，一个月可以节省了几个小时的时间呢。
自定义 有许多你重要的工具（比如你的文本编辑器）会允许你自定义它们的界面，这样不仅仅可以让界面符合你个人的使用习惯，甚至可以加强与别的工具的协同效应。比如说，你是一个 vim 使用者，你经常使用 j 和 k 进行上下移动，那为什么不尝试安装 chrome 插件让你可以在 chrome 里使用一样的快捷键呢？ 你甚至可以不止步于简单的键盘绑定。许多工具都有脚本语言或扩展框架让你可以自己写代码去自定义工具。当然这比简单的键盘绑定花费更多的时间，但是这是一个能够让你明白工具内部运行的好方法，也是一个启动开源项目的好机会，这些都可以让你的简历锦上添花。
可移植的配置 你安装了所有工具，学了所有的键盘绑定，把它们都自定义化了。 但是突然，你被迫要在一个远程机器或者新电脑上工作，那前面所有努力都白费了，你要从 0 开始，对吗？ 那如果你不仅仅自定义了你的工具，还把相应的配置都变得轻便可以移植了呢？许多工具拥有包含工具配置参数的 .rc 文件或者配置文件。这个可以允许你把它们放到源代码控制里面，或分享到其它机器其它仓库里面。你只需要用脚本把它们关联到正确的位置，让你大多数的配置在两步命令中启动-克隆你的仓库，运行脚本，然后，你就可以开始工作了。
这是一个很好的类似的例子
减少文本切换 最后一个方法是最小化你切换工具的时间。 在你其实只需要看几行代码的时候，你真的需要把终端放大到占满整个屏幕吗？
尝试一下使用不同的窗口界面、不同的屏幕数量和不同的工作区设置，来帮你你找到一套最适用于你的解决方案。你可以在不同的工作场景使用几套不同的预设置界面。像我，我写代码和调试的时候会使用一套窗口设置，在读代码和审核代码时会使用另一套。切换它们也是关联了一个热键。
结论 你的工具就是你的扩展，就像你的其它部位，需要投资和实践去改善。 如果你有时会因为你过时的工作流而感到沮丧，或者只是想挤出更多的时间，我希望我这篇文章可以在如何改善你的日常工作工具使用上给到帮助。</description>
    </item>
    
    <item>
      <title>Control_startup_and_shutdown_order_in_Compose</title>
      <link>https://codenow.me/translation/control_startup_and_shutdown_order_in_compose/</link>
      <pubDate>Sun, 07 Apr 2019 23:54:05 +0800</pubDate>
      
      <guid>https://codenow.me/translation/control_startup_and_shutdown_order_in_compose/</guid>
      <description>原文链接：https://docs.docker.com/compose/startup-order/，翻译如下：
您可以使用“depends_on”选项控制服务启动和关闭的顺序。compose总是按依赖顺序启动和停止容器，依赖性由depends_on、links、volumes_form和网络模式“service:…”确定。
但是，对于启动，compose不会等到容器“就绪”（对于特定的应用程序来说，这意味着什么）之后才运行。这是有充分理由的。
等待数据库（例如）准备就绪的问题实际上只是分布式系统中一个更大问题的子集。在生产环境中，数据库可能随时不可用或移动主机。您的应用程序需要能够适应这些类型的故障。
要处理此问题，请设计应用程序以尝试在失败后重新建立与数据库的连接。如果应用程序重试连接，它最终可以连接到数据库。
最好的解决方案是在应用程序代码中执行这种签入，无论是在启动时还是在任何时候由于任何原因而丢失连接。但是，如果您不需要这种级别的恢复能力，您可以使用包装脚本来解决这个问题：
 使用诸如wait for it、dockerize或sh-compatible wait for等工具。这些是小包装脚本，您可以将其包含在应用程序的映像中，以轮询给定的主机和端口，直到它接受TCP连接。  例如，要使用wait-for-it.sh或wait-for-wrap服务的命令：
version: &amp;quot;2&amp;quot; services: web: build: . ports: - &amp;quot;80:8000&amp;quot; depends_on: - &amp;quot;db&amp;quot; command: [&amp;quot;./wait-for-it.sh&amp;quot;, &amp;quot;db:5432&amp;quot;, &amp;quot;--&amp;quot;, &amp;quot;python&amp;quot;, &amp;quot;app.py&amp;quot;] db: image: postgres   提示：第一个解决方案有局限性。例如，它不验证特定服务何时真正准备好。如果向命令添加更多参数，请使用带有循环的bash shift命令，如下一个示例所示。
  或者，编写自己的包装器脚本来执行更特定于应用程序的健康检查。例如，您可能希望等待Postgres完全准备好接受命令：  #!/bin/sh # wait-for-postgres.sh set -e host=&amp;quot;$1&amp;quot; shift cmd=&amp;quot;$@&amp;quot; until PGPASSWORD=$POSTGRES_PASSWORD psql -h &amp;quot;$host&amp;quot; -U &amp;quot;postgres&amp;quot; -c &#39;\q&#39;; do &amp;gt;&amp;amp;2 echo &amp;quot;Postgres is unavailable - sleeping&amp;quot; sleep 1 done &amp;gt;&amp;amp;2 echo &amp;quot;Postgres is up - executing command&amp;quot; exec $cmd  您可以将其用作包装脚本，如前一个示例中所示，方法是设置：</description>
    </item>
    
    <item>
      <title>Five Simple Strategies for Securing APIs</title>
      <link>https://codenow.me/translation/five-simple-strategies-for-securing-apis/</link>
      <pubDate>Sun, 07 Apr 2019 23:54:05 +0800</pubDate>
      
      <guid>https://codenow.me/translation/five-simple-strategies-for-securing-apis/</guid>
      <description>保护API的五个简单策略 验证参数 任何弹性API实现的第一步是清理所有传入数据以进行确认它是有效的，不会造成伤害。对参数唯一最有效的防御操作和注入攻击时针对严格的模式验证所有传入的数据有效地描述了被认为是系统允许的输入。模式验证应尽可能具有限制性，尽可能使用输入、范围、集合甚至显性列表。还要考虑从许多开发工具生产的自动生成的模式通常会将所有参数减少到过于宽泛而无法有效识别潜在威胁的模型。手工构建的白名单时更优选的，因为开发人员可以根据他们对应用程序所期望的数据模型的理解来约束输入。基于XML的内容类型的一个选项是使用XML模式语言，该语言在创建受限制的内容模型和高度受约束的结构方面非常有效。对于日益普遍的JSON数据类型，有几种JSON模式描述语言。虽然没有XML那么丰富，但JSON的编写和理解要简单的多，提供透明度使其安全度提高。
应用显示威胁检测 良好的模式验证可以防止许多注入攻击，但也要考虑显示扫描常见的攻击签名。SQL注入或脚本注入攻击经常通过扫描原始输入容易发现的常见模式来进行攻击。 同时考虑可能采取其他形式，例如拒绝服务（DoS）。利用网咯基础设施俩发现和缓解网络级DoS攻击，还可以检查利用参数的DoS攻击。庞大的信息、严重嵌套的数据结构或过于复杂的数据结构都可能导致有效的拒绝服务攻击，从而不必要地消耗受影响的API服务器上的资源。将病毒检测应用于所有潜在风险的编码内容。文件传输中涉及的API硬解码base64附件并将其提交到服务器级病毒扫描，然后再保存到文件系统，在这些文件系统中可能会无意中激活它们。
始终开启SSL 使SSL / TLS成为所有API的规则。 在21世纪，SSL并不奢侈; 这是一个基本要求。 添加SSL / TLS并正确应用它可以有效抵御中间人攻击的风险。 SSL / TLS为客户端和服务器之间交换的所有数据提供完整性，包括重要的访问令牌，例如OAuth中使用的令牌。 它可选地使用证书提供客户端身份验证，这在许多环境中很重要。
应用严格的身份验证和授权 用户和应用程序标识是必须单独实现和管理的概念。 考虑基于广泛身份上下文的授权，包括实际因素，例如传入IP地址（如果已知是固定的或在特定范围内），访问时间窗口，设备标识（对移动应用程序有用），地理位置等。 OAuth正在迅速成为以用户为中心的API授权的首选资源，但它仍然是一个复杂，快速变化和困难的技术。 开发人员应该遵循基本的，易于理解的OAuth用例，并始终使用现有的库而不是尝试构建自己的库。
使用经过验证的Solutions 安全的第一条规则是：不要发明自己的。 没有理由创建自己的API安全框架，因为API已经存在优秀的安全解决方案。 挑战在于正确应用它们。</description>
    </item>
    
    <item>
      <title>更详细的 Go 性能测试</title>
      <link>https://codenow.me/translation/beachmark-details/</link>
      <pubDate>Sun, 07 Apr 2019 20:22:05 +0800</pubDate>
      
      <guid>https://codenow.me/translation/beachmark-details/</guid>
      <description>我一直在优化我的 go 代码并且一直优化我的性能测试方案。
让我们先看一个简单的例子：
func BenchmarkReport(b *testing.B) { runtime.GC() for i := 0; i &amp;lt; b.N; i++ { r := fmt.Sprintf(&amp;#34;hello, world %d&amp;#34;, 123) runtime.KeepAlive(r) } } 执行 go test -beach . 会看到这样子的结果：
BenchmarkReport-32 20000000 107 ns/op  这可能可以初略的估计性能表现，但是彻底的优化需要更详细的结果。
将所有的内容压缩成一个数字必然是简单的。
让我向你们介绍我写的 hrtime 包，以便于获取更详细的性能测试结果。
直方图 第一个推荐使用的是 hrtime.NewBeachmark，重写上面的简单例子：
func main() { bench := hrtime.NewBenchmark(20000000) for bench.Next() { r := fmt.Sprintf(&amp;#34;hello, world %d&amp;#34;, 123) runtime.KeepAlive(r) } fmt.Println(bench.Histogram(10)) } 它会输出：
avg 372ns; min 300ns; p50 400ns; max 295µs; p90 400ns; p99 500ns; p999 1.</description>
    </item>
    
    <item>
      <title>人脸识别如何工作</title>
      <link>https://codenow.me/translation/how-does-facial-recognition-work/</link>
      <pubDate>Sun, 07 Apr 2019 20:34:14 +0900</pubDate>
      
      <guid>https://codenow.me/translation/how-does-facial-recognition-work/</guid>
      <description>How does facia recognition work? (原文地址)[https://us.norton.com/internetsecurity-iot-how-facial-recognition-software-works.html]
By Steve Symanovich
面部识别是一种通过技术识别人脸的方式。面部识别系统使用生物识别技术来映射来自照片或视频的面部特征。它将信息与已知面部数据库进行比较以找到匹配项。面部识别可以帮助验证个人身份，但它也会引发隐私问题。
面部识别市场预计将从2017年的40亿美元增长到2022年的77亿美元。这是因为面部识别具有各种商业应用。它可用于从监控到营销的各个方面。
但这就是它变得复杂的地方。如果隐私对您很重要，您可能希望控制您的个人信息（您的数据）的使用方式。事情就是这样：你的“面子”是数据。
面部识别的工作原理 你可能善于识别面孔。您可能会发现很难找到家人，朋友或熟人的面孔。你熟悉他们的面部特征 - 他们的眼睛，鼻子，嘴巴 - 以及他们如何走到一起。
这就是面部识别系统的工作方式，但是在一个宏大的算法规模上。在您看到面部的地方，识别技术会看到数据。可以存储和访问该数据。例如，根据乔治敦大学的一项研究，一半的美国成年人将他们的图像存储在执法机构可以搜索的一个或多个面部识别数据库中。
那么面部识别是如何工作的呢？技术各不相同，但以下是基本步骤：
第1步。从照片或视频中捕获您的脸部照片。你的脸可能会单独或在​​人群中出现。您的图像可能会显示您正向前看或几乎在剖面图中。
第2步。面部识别软件可读取您脸部的几何形状。关键因素包括眼睛之间的距离以及从额头到下巴的距离。该软件识别面部标志 - 一个系统识别其中的68个 - 这是区分您的面部的关键。结果：你的面部特征。
第3步。您的面部特征 - 数学公式 - 与已知面部的数据库进行比较。并考虑到这一点：至少有1.17亿美国人在一个或多个警察数据库中有他们的面孔图像。根据2018年5月的一份报告，联邦调查局已经获得了4.12亿张用于搜索的面部图像。
第4步。做出决定。您的面部印记可能与面部识别系统数据库中的图像相匹配。
一般来说，面部识别是如何运作的，但谁使用它？
谁使用面部识别？ 许多人和组织使用面部识别 - 并且在许多不同的地方。这是一个抽样：
美国政府机场。面部识别系统可以监控机场来来往往的人员。美国国土安全部使用该技术识别逾期签证或可能受到刑事调查的人。华盛顿杜勒斯国际机场的海关官员于2018年8月首次使用面部识别器进行了逮捕，抓住了一名试图进入该国的冒名顶替者。 手机制造商的产品。Apple首先使用面部识别来解锁其iPhone X，并继续使用iPhone XS。面部身份验证 - 确保您在访问手机时成为现实。苹果表示，随机面部解锁手机的可能性大约为百万分之一。 大学在课堂上。面部识别软件本质上可以采取滚动。如果你决定削减课程，你的教授可以知道。甚至不要想让你聪明的室友接受考试。 网站上的社交媒体公司。当您将照片上传到其平台时，Facebook会使用算法来识别面部。社交媒体公司询问您是否要在照片中标记人物。如果您同意，则会创建指向其个人资料的链接。Facebook可以识别98％准确率的面孔。 入口和禁区内的企业。一些公司已经交易面部识别系统的安全徽章。除了安全性，它可能是与老板面对面交流的一种方式。 宗教场所的宗教团体。教会使用面部识别来扫描他们的会众，看看谁在场。这是跟踪常客和不那么常客的好方法，也是帮助定制捐赠请求的好方法。 商店中的零售商。零售商可以结合监控摄像头和面部识别来扫描购物者的面部。一个目标：识别可疑角色和潜在的扒手。 航空公司在登机口。您可能习惯于让代理人在登机口扫描登机牌以登机。至少有一家航空公司扫描你的脸。 营销活动中的营销人员和广告客户。营销人员在针对产品或创意的群组进行定位时，通常会考虑性别，年龄和种族等因素。面部识别可以用来定义那些观众甚至在音乐会之类的东西。</description>
    </item>
    
    <item>
      <title>Tidb Proposal: A new aggregate function execution framework</title>
      <link>https://codenow.me/translation/tidb-proposal-a-new-aggregation-function-execution-framework/</link>
      <pubDate>Sun, 07 Apr 2019 16:09:38 +0800</pubDate>
      
      <guid>https://codenow.me/translation/tidb-proposal-a-new-aggregation-function-execution-framework/</guid>
      <description>原文链接 Proposal: A new aggregate function execution framework
摘要 这篇 proposal 提出了一种的聚合计算执行框架，用来提高聚合函数的执行性能。
背景 在 release-2.0 版本中，聚合计算框架在 expression/aggregation 模块中。在这个框架中，所有的聚合函数都实现了 Aggregation 接口。所有的聚合函数使用 AggEvaluateContext 来保存聚合计算的中间结果(partial result）。AggEvaluateContext 中的 DistinctChecker 字段使用 byte 数组作为 key，用来对相同分组中的数据进行去重。在执行过程中， Update 接口会被调，为每行数据计算和更新中间结果。在执行过程中，它为每个聚合函数枚举每种可能的聚合状态，这回带来大量的 CPU 分支检测。
在这个框架下，可以很简单的实现一个新的聚合函数。但是它也有很多缺点：
 Update 方法会为每条数据被调用。每次调用中都可能会带来大量开销，特别是执行过程中包含了上万条数据的时候。 Update 方法会为每种计算状态调用，这也会带来大量的 CPU 分支检测。比如， AVG 函数在 Partial1 和 Final 状态下行为是不一样的，Update 方法不得不使用 switch 语句来处理所有可能的状态。 GetResult 方法返回 types.Datum 类型作为每个分组的最终结果。在执行阶段，TiDB 目前使用 Chunk 来保存数据。使用了 aggregation 框架，不得不将返回的 Datum 类型转换成 Chunk ，这会带来大量的数据转换和内存分配工作。 AggEvaluateContext 用来保存每组分组数据的最终结果，相比实际所需，这会消耗更多的内存。比如 COUNT 函数原本只需要一个 int64 字段来保存行数。 distinctChecker 用来为数据去重，它使用的是 byte 数组作为 key。针对输入数据的 encoding 和 decoding 操作会带来大量的 CPU 开销，其实这个问题可以通过直接使用输入数据作为 key 来避免掉。  方案 在这个 PR 中 https://github.</description>
    </item>
    
    <item>
      <title>不用一小时，加密你的整个人生</title>
      <link>https://codenow.me/translation/howtoencryptyourentirelifelessthanonehour/</link>
      <pubDate>Sun, 07 Apr 2019 14:26:14 +0900</pubDate>
      
      <guid>https://codenow.me/translation/howtoencryptyourentirelifelessthanonehour/</guid>
      <description>不用一小时，加密你的整个人生 作者：Quincy Larson How to encrypt your entire life in less than an hour 
前言略 全文有精简
好，让我们开始吧！ 首先，解释几个术语。 Attacker：所有未经本人同意却尝试获取本人数据的人或组织，甚至政府。 Private/secure：理想很丰满，现实是只要人类参与，没有任何系统可以保证百分百隐私或安全。
只要你的手机、电脑 、账户受到充分保护，它们的内容会保持在一个加密的状态，那无论其他人多么强大，也无法可施。
Tip1: 对你的收件箱进行两步验证 你的收件箱是你生活的主钥。如果入侵者解开了它，那他不仅可以读取你的邮件，还可以通过重置你的密码去做更多的事，包括社交账户甚至银行账户。 你仅仅需要通过一个很简单的操作就可以大大改善你的个人隐私，就是去开启你收件箱的两步验证。 基本上两步验证就是你登录后的第二层保护。通常当你登录你的账户时，你会收到一条验证码。 两步验证基本上可以减少你收件箱被黑的可能性。 如果你用的是 gmail，你应该开启两步验证
说真的，现在就去开启吧，我在这等你回来。
Tip2: 加密你的硬盘 Windows 和 Macos 都有内置全盘加密。你只需要开启它。
Tip3: 开启你手机的密码保护 指纹验证比其他方法都好，但是还不足够。 第五修订法允许你可以对你的密码进行保密，但是法院可以强迫你用指纹解锁手机（美国法律）。 而且，你的指纹是唯一的，不能在入侵者掌控你的指纹信息后进行更改。 一般入侵者会在手机完全锁住前有十次尝试机会。所以如果你的 4 个数字的密码属于以下常见的这些之一的话，请修改你的密码。
1234 9999 1111 3333 0000 5555 1212 6666 7777 1122 1004 1313 2000 8888 4444 4321 2222 2001 6969 1010  如果为了方便还是坚持使用指纹验证的话，万一被逮捕，请马上关机。当他们重启手机，因为没有你的密码，他们也没办法解锁你的手机。（接前面美国法律的事）
Tip4: 不同的设备用不同的密码 密码本质上就是不安全的 Mark Zuckerberg 曾经用 ‘dadada’ 作为 他的 Linkedin 账户密码。 早些年，有黑客对外开放 117 百万个邮箱密码关联，他就是受害者之一。 黑客可以使用他的邮箱和密码去获取 Twitter 和 Pinterest 的登录。 所以，一个设备用一个密码。 当然，你没可能记得住那么多的密码，你可以使用工具 password manager</description>
    </item>
    
    <item>
      <title>Go Context 在 HTTP 传播</title>
      <link>https://codenow.me/translation/http-propagation-context/</link>
      <pubDate>Sun, 31 Mar 2019 22:12:54 +0800</pubDate>
      
      <guid>https://codenow.me/translation/http-propagation-context/</guid>
      <description>Go 1.7 引入了一个内置的 context 类型，在系统中可以使用 Context 来传递元数据，例如不同函数或者不同线程甚至进程的传递 Request ID。
Go 将 Context 包引入标准库以统一 context 的使用。在此之前每个框架或者库都有自己的 context 。它们之间还无法兼容，导致了碎片化，最终在各处 context 的传播上就有不少的麻烦。
虽然在同一个处理过程中有一个通用的 context 传播机制是非常有用的，但是 Go 的 Context 包并没有提供该功能。就像上面描述的，context 会在网络中被不同的处理过程传递。例如在多服务架构中，一个请求往往会在多个地方被处理 (多个微服务，消息队列，数据库等)，直到最后响应给用户。能够在多个处理过程中传递 context 显得尤为重要。
如果你要在 HTTP 中传播 context ，需要你对 context 进行序列化处理。类似的，在接收端也要解析，同时把值放入当前的 context 中。假设我们希望在 context 中传递 request ID。
package request import &amp;#34;context&amp;#34; // WithID 把 request ID 放入当前的 context 中 func WithID(ctx context.Context, id string) context.Context { return context.WithValue(ctx, contextIDKey, id) } // IDFromContext 返回从 context 中获取的 request ID // 如果 context 中没有定义就返回空值 func IDFromContext(ctx context.</description>
    </item>
    
    <item>
      <title>TiDB Proposal: Support Skyline Pruning</title>
      <link>https://codenow.me/translation/tidb-proposal-support-skyline-pruning/</link>
      <pubDate>Sun, 31 Mar 2019 13:31:09 +0800</pubDate>
      
      <guid>https://codenow.me/translation/tidb-proposal-support-skyline-pruning/</guid>
      <description>原文链接：Proposal: Support Skyline Pruning，翻译如下：
摘要 这篇建议引入了一些启发式规则和一个针对消除访问路径 (access path) 的通用框架。通过它的帮助，优化器可以避免选择一些错误的访问路径。
背景 目前，访问路径的选择很大程度上取决于统计信息。我们可能会因为过期的统计信息而选择错误的索引。然而，很多错误的选择是可以通过简单的规则来消除的，比如：当主键或者唯一性索引能够完全匹配的时候，我们可以直接选择它而不管统计信息。
建议 (Proposal) 目前在选择访问路径时最大的因素是需要扫描的数据行数，是否满足物理属性 (physical property) ，以及是否需要两次扫描。在这三个因素当中，只有扫描行数依赖统计信息。那么在没有统计信息的情况下我们能够怎样比较扫描行数呢？让我们来看一下下面这个例子：
create table t(a int, b int, c int, index idx1(b, a), index idx2(a)); select * from t where a = 1 and b = 1; 从查询和表结构上，我们能够看到使用索引 idx1 扫描能够覆盖 idx2，通过索引 idx1 扫描的数据行数不会比使用 idx2 多，所以在这个场景中，idx1 要比 idx2 好。
我们如何综合这三个因素来消除访问路径呢？假如有两条访问路径 x 和 y，如果 x 在这几个方面都不比 y 差并且某个因素上 x 还好于 y，那么在使用统计数据之前，我们可以消除 y，因为 x 在任何情况下都一定比 y 更好。这就是所谓的 skyline pruning。</description>
    </item>
    
    <item>
      <title>Intro to Python Lambda Functions</title>
      <link>https://codenow.me/translation/intro_to_python_lambda_functions/</link>
      <pubDate>Sat, 30 Mar 2019 17:14:57 +0800</pubDate>
      
      <guid>https://codenow.me/translation/intro_to_python_lambda_functions/</guid>
      <description>原文地址: https://www.pythonforthelab.com/blog/intro-to-python-lambda-functions/
不久前，Python在其语法中引入了使用lambda而不是def来定义函数的可能性。这些函数称为匿名函数同，在其它语言(如javascript)中非常常见。然后，在Python中，它们看起来有点晦涩，经常被忽略或误用。在本文中，我们将介绍labda函数，并讨论在何处以及如何使用它。
要定义一个函数，可以使用以下语法：
def average(x, y): return (x + y) / 2 然后，如果要计算两个数字的平均值，只需执行以下操作
avg = average(2, 5) 在这种情况下，平均值将为3.5。我们也可以这样定义平均值：
average = lambda x, y: (x + y) / 2 如果你测试此函数，您将看到输出完全一样。必须指出，def和lambda之间语法非常不同。首先，我们定义不带括号的参数x, y。然后，我们定义要应用的操作。注意，当使用lambda函数时，返回是隐式的。
然而，还有更根本的区别。lambda函数只能在一行上表示，并且没有docstring。如果对上面的每个定义尝试help(average)，您将看到输出非常不同，此外，无法记录average的第二版的实际操作。
从功能上讲，定义平均值的两种方法都给出了相同的结果。到目前为止，他们之间的差异非常微妙。lambda（或匿名）函数的主要优点是它们不需要名称。此外，像我们上面所做的那样指定一个名字被认为是不好的做法，我们稍后将讨论。现在让我们看看您希望在什么上下文中使用lambda函数而不是普通函数。
大多数教程都侧重于lambda函数来对列表进行排序。在讨论其他主题之前，我们也可以这样做。假设您有以下列表：
var=[1，5，-2，3，-7，4] 假设您希望对值进行排序，可以执行以下操作：
sorted_var = sorted(var) #[-7，-2，1，3，4，5] 这很容易。但是，如果您希望根据到给定数字的距离对值进行排序，会发生什么情况呢？如果要计算到1的距离，需要对每个数字应用一个函数，例如abs（x-1），并根据输出对值进行排序。幸运的是，排序后，您可以使用关键字参数key=执行此操作。我们可以做到：
def distance(x): return abs(x - 1) sorted_var = sorted(var, key=distance) # [1, 3, -2, 4, 5, -7] 另一种选择是使用lambda函数：
sorted_var = sorted(var, key=lambda x: abs(x-1)) 这两个例子将产生完全相同的输出。在使用def或lambda定义函数之间没有功能差异。我可以说第二个例子比第一个稍微短一些。此外，它使代码更具可读性，因为您可以立即看到对每个元素（abs（x-1））所做的操作，而不是通过代码挖掘来查看定义的距离。
另一种可能是与map结合使用。map是将函数应用于列表中的每个元素的一种方法。例如，基于上面的示例，我们可以执行以下操作：
list(map(distance, var)) # [0, 4, 3, 2, 8, 3] 或者，使用lambda表达式</description>
    </item>
    
    <item>
      <title>Scikit-Learn</title>
      <link>https://codenow.me/translation/scikit-learn/</link>
      <pubDate>Sat, 30 Mar 2019 10:44:57 +0800</pubDate>
      
      <guid>https://codenow.me/translation/scikit-learn/</guid>
      <description>Scikit-learn: Machine Learning in Python 最近在学习机器学习算法和深度学习的部分内容。于是将Scikit-Learn的相关介绍论文看了看，翻译了一部分。原文地址
摘要 Scikit-learn是一个Python模块，集成了各种最先进的机器学习算法，适用于中等规模和无监督的问题。该软件包侧重于使用通用高级语言将机器学习引入非专业人员。重点在于易于使用，性能，文档以及API的一致性。它具有最小的依赖性，并在简化的BSD许可下分发，鼓励在学术和商业环境中使用它。二进制文件和文档可以从http://scikit-learn.sourceforge.net 下载。
介绍 Python编程语言正在成为最流行的科学计算语言之一。由于其高水平的交互性和成熟的科学库生态系统，Python在算法开发和探索数据分析领域成为极有吸引力的选择。然而，作为一种通用语言，它不仅越来越多的应用于学术领域，也应用于工业。Scikit-learn利用这种环境提供许多出名的机器学习算法的最先进的实现方式，同时保持易于使用的界面以及和Python语言紧密集成。这满足了软件和网络行业的非专业人员以及计算机科学以外领域（如生物学或物理学）对统计数据分析的日益增长的需求。
Scikit-learn不同于其他Python的机器学习库的原因在于：
 它根据BSD许可证分发。 与DMP和pybrain不同，它结合了编译代码来提升效率。 它仅仅依赖于Numpy和Scipy来促进易于分发。不像pymvpa那样拥有例如R和shogun这样的可选依赖项。 与使用数据流框架的pybrain不同，它侧重于命令式编程。虽然该软件包主要是用Python编写的，但它包含了C ++库LibSVM和LibLinear，它们提供了SVMS的参考实现和具有兼容许可的广义线性模型。二进制包可在包括Windows和任何POSIX平台在内的丰富平台上使用。此外，由于其自由许可，它已被广泛分发为主要的免费软件发行版，如Ubuntu，Debian，Mandriva，NetBSD和商业广告诸如“Enthought Python Distributions”之类的发行版。  项目愿景 代码质量。该项目的目标不是提供尽可能多的功能，而是提供可靠的实施能力。通过单元测试来保证代码质量。在发布的0.8版本，测试覆盖率为81%，与此同时，使用静态分析工具例如pyflakes和PEP8.最后，我们严格遵守Python编程指南和Numpy样式文档中使用的函数与参数命名，努力保持一致性。
BSD许可。大多数Python生态系统都是用非copyleft许可证进行许可。虽然这种政策有利于商业项目采用这些工具，但它确实施加了一些限制：我们无法使用某些现有的科学代码，例如GSL。
裸骨设计和API。 为了降低进入门槛，我们避免使用框架代码并将不同对象的数量保持在最低限度，依赖于数据容器的numpy数组。
社区驱动的发展。 我们的开发基于git，GitHub和公共邮件列表等协作工具。 欢迎并鼓励外部捐助。
开发者文档。Scikit-learn提供了约300页的用户指南，包括叙述文档，类参考，教程，安装说明，以及60多个示例，其中一些包含实际应用程序。 我们尽量减少机器学习术语的使用，同时主要训练精度与所使用的算法有关。
基础技术 Numpy：数据和模型参数的基础数据结构用户。 输入数据表示为numpy数组，因此可以与其他科学Python库无缝集成。 Numpy的基于视图的内存模型限制了副本，即使与编译代码绑定也是如此。它还提供基本的算术运算。
Scipy：线性代数的有效算法，稀疏矩阵表示，特殊函数和基本统计函数。 Scipy具有许多基于Fortran的标准数字包的绑定，例如LAPACK。 这对于易于安装和可移植性非常重要，因为围绕Fortran代码提供库在各种平台上都具有挑战性。
Cython：一种在Python中组合C的语言。 Cython使用类似Python的语法和高级操作轻松实现编译语言的性能。 它还用于绑定已编译的库，从而消除了Python / C扩展的样板代码。
总结 Scikit-learn使用一致的，面向任务的界面，公开了各种机器学习算法，包括监督和非监督，从而可以轻松地比较给定应用程序的方法。 由于它依赖于科学的Python生态系统，因此可以轻松地将其集成到传统统计数据分析范围之外的应用程序中。 重要的是，以高级语言实现的算法可以用作特定于用例的方法的构建块，例如，在医学成像中。 未来的工作包括在线学习，扩展到大型数据集。</description>
    </item>
    
    <item>
      <title>把项目从 Dep 迁移到 Go Modules</title>
      <link>https://codenow.me/translation/migrating-projects-from-dep-to-go-modules/</link>
      <pubDate>Sun, 24 Mar 2019 23:48:57 +0800</pubDate>
      
      <guid>https://codenow.me/translation/migrating-projects-from-dep-to-go-modules/</guid>
      <description>原文地址
Go Modules 是 Go 管理的未来方向。已经在 Go 1.11 中可以试用，将会是 Go 1.13 中的默认行为。
我不会在这篇文章中描述包管理工具的工作流程。我会主要讨论的是如何把现有的项目中 dep 迁移的 Go Module。
在我的实例中，我会使用一个私有的仓库地址 github.com/kuinta/luigi ，它是使用 Go 语言编写，在好几个项目中被使用，是一个绝佳的候选人。
首先，我们需要初始化 Module：
cd github.com/kounta/luigi go mod init github.com/kounta/luigi 完成后只会有两行输出：
go: create now go.mod: module github.com/kounta/luigi go: copying requirments from Gopkg.lock 是的，这样就对了。这样就已经完成从 dep 迁移了。
现在你只要看一眼新生成的文件 go.mod 就像下面这样：
module github.com/kounta/luigi go 1.12 require ( github.com/elliotchance/tf v1.5.0 github.com/gin-gonic/gin v1.3.0 github.com/go-redis/redis v6.15.0+incompatible )  其实在 require 中还有更多的内容，为了保持整洁我把他们删除了。
就像 dep 区分 toml 和 lock 文件一样。我们需要生成 go.</description>
    </item>
    
    <item>
      <title>Group by and Aggregation Elimination</title>
      <link>https://codenow.me/translation/group-by-and-aggregation-elimination/</link>
      <pubDate>Thu, 21 Mar 2019 11:31:17 +0800</pubDate>
      
      <guid>https://codenow.me/translation/group-by-and-aggregation-elimination/</guid>
      <description>原文链接：Group-by and Aggregation Elimination 是一篇关于数据库查询优化的文章，有几句话实在不知道咋翻译好，也影响不大，直接留下原句了。翻译如下：
I get a fair number of questions on query transformations, and it’s especially true at the moment because we’re in the middle of the Oracle Database 12c Release 2 beta program. 有时用户可能会发现在一个执行计划里有些环节消失了或者有些反常，然后会意识到查询发生了转换 (transformation) 。举个例子，有时你会惊讶的发现，查询语句里的表和它的索引可能压根就没有出现在查询计划当中，这是连接消除 (Join Elimination) 机制在起作用。
我相信，你已经发现查询转换是查询优化中很重要的一环，因为它经常能够通过消除一些像连接（join）、排序（sort）的步骤来降低查询的代价。有时修改查询的形式可以让查询使用不同的访问路径（access path），不同类型的连接和甚至完全不同的查询方式。在每个发布版本附带的优化器白皮书中（比如 Oracle 12c One 的），我们都介绍了大多数的查询转换模式。
在 Oracle 12.1.0.1 中，我们增加了一种新的转换模式，叫做 Group-by and Aggregation Elimination ，之前一直没有提到。它在 Oracle 优化器中是最简单的一种查询转换模式了，很多人应该都已经很了解了。你们可能在 Mike Dietrich’s upgrade blog 中看到过关于它的介绍。让我们来看一下这种转换模式到底做了什么。
很多应用都有用过这么一种查询，这是一种单表分组查询的形式，数据是由另一个底层的分组查询形成的视图来提供的。比如下面这个例子：
SELECT v.column1, v.column2, MAX(v.sm), SUM(v.sm) FROM (SELECT t1.</description>
    </item>
    
  </channel>
</rss>